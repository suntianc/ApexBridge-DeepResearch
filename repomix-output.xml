This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
app/
  api/
    __init__.py
    history.py
    research.py
  core/
    __init__.py
    config.py
    llm.py
    utils.py
  modules/
    debate/
      __init__.py
      mad_framework.py
    insight/
      __init__.py
      prompts.py
    knowledge/
      __init__.py
      file_store.py
    orchestrator/
      __init__.py
      dag.py
      graph.py
      state.py
    perception/
      __init__.py
      crawler.py
      search.py
    utils/
      file_utils.py
    verification/
      __init__.py
      verification_agent.py
    __init__.py
  __init__.py
  worker.py
image/
  banner.png
test/
  test_runner.py
.env.example
.gitignore
.repomixignore
LICENSE
main.py
repomix.config.json
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(mkdir:*)",
      "Bash(python:*)",
      "Bash(tree:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(find:*)",
      "Bash(python3 -m py_compile:*)",
      "Bash(python3 -c:*)",
      "Bash(pip3 install -r requirements.txt 2>&1:*)",
      "Bash(cat:*)",
      "Bash(git push:*)"
    ]
  }
}
</file>

<file path="app/core/utils.py">
# app/core/utils.py
"""å…¬å…±å·¥å…·å‡½æ•°"""
import json
import re
from typing import Optional


def parse_json_safe(text: str) -> Optional[dict | list]:
    """
    å®‰å…¨åœ°è§£æ JSON å­—ç¬¦ä¸²ï¼Œå¤„ç†å„ç§æ ¼å¼é—®é¢˜

    æ”¯æŒçš„æ ¼å¼:
    - çº¯ JSON: {"key": "value"}
    - Markdown JSON: ```json {"key": "value"} ```
    - JSON Array: [{"id": 1}, {"id": 2}]
    - JSON in text: Some text {"key": "value"} more text

    Args:
        text: å¯èƒ½åŒ…å« JSON çš„æ–‡æœ¬

    Returns:
        è§£æåçš„ dict/listï¼Œå¤±è´¥è¿”å› None
    """
    if not text:
        return None

    try:
        # 1. å°è¯•ç›´æ¥è§£æï¼ˆæ¸…ç† markdown ä»£ç å—ï¼‰
        clean = text.replace("```json", "").replace("```", "").strip()
        return json.loads(clean)
    except json.JSONDecodeError:
        pass

    # 2. å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON å¯¹è±¡æˆ–æ•°ç»„
    match = re.search(r'(\{.*\}|\[.*\])', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(0))
        except json.JSONDecodeError:
            pass

    return None
</file>

<file path="app/modules/knowledge/file_store.py">
# app/modules/knowledge/file_store.py
import os
import hashlib
import json
from glob import glob
from datetime import datetime
from typing import List, Dict
from app.core.config import settings

class FileKnowledgeStore:
    def __init__(self):
        self.root_dir = settings.TASK_STORAGE_DIR

    def _get_task_dir(self, task_id: str) -> str:
        path = os.path.join(self.root_dir, task_id, "docs")
        os.makedirs(path, exist_ok=True)
        return path

    def _get_filename(self, content: str, url: str) -> str:
        """
        ğŸŸ¢ ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨å†…å®¹çš„ MD5 è¿›è¡Œå»é‡ã€‚
        å¦‚æœå†…å®¹ä¸€æ ·ï¼Œä¸ç®¡ URL å˜æ²¡å˜ï¼Œéƒ½è§†ä¸ºåŒä¸€ä¸ªæ–‡ä»¶ã€‚
        """
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()[:12]
        return f"doc_{content_hash}.md"

    def add_documents(self, documents: List[Dict], task_id: str):
        task_dir = self._get_task_dir(task_id)
        count = 0
        
        for doc in documents:
            content = doc.get("content", "")
            if len(content) < 50: continue

            # ä½¿ç”¨å†…å®¹å“ˆå¸Œç”Ÿæˆæ–‡ä»¶å
            filename = self._get_filename(content, doc.get("url", ""))
            filepath = os.path.join(task_dir, filename)

            # å†…å®¹çº§å»é‡
            if os.path.exists(filepath):
                continue

            # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºä¿å­˜æ—¶é—´
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            md_content = f"""---
url: {doc.get('url')}
source: {doc.get('source', 'web')}
saved_at: {current_time}
---

{content}
"""
            try:
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(md_content)
                count += 1
            except Exception as e:
                print(f"âŒ [FileStore] Write error: {e}")

        if count > 0:
            print(f"ğŸ’¾ [FileStore] Saved {count} new documents to {task_dir}")

    # ğŸŸ¢ è¡¥å…¨ç¼ºå¤±çš„æ–¹æ³•ï¼šè·å–æ–‡ä»¶åˆ—è¡¨
    def list_files(self, task_id: str) -> List[str]:
        task_dir = self._get_task_dir(task_id)
        # æŒ‰æ–‡ä»¶åæ’åºç¡®ä¿é¡ºåºä¸€è‡´
        return sorted(glob(os.path.join(task_dir, "*.md")))

    # ğŸŸ¢ è¡¥å…¨ç¼ºå¤±çš„æ–¹æ³•ï¼šè¯»å–å•ä¸ªæ–‡ä»¶
    def read_file(self, filepath: str) -> str:
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            print(f"âŒ Error reading file {filepath}: {e}")
            return ""

    # è¿™ä¸ªæ–¹æ³•ä¿ç•™ä½œä¸ºå¤‡ç”¨ï¼Œæˆ–è€…ç»™ Critic ç”¨
    def get_all_context(self, task_id: str) -> str:
        files = self.list_files(task_id)
        context = []
        for f in files:
            context.append(self.read_file(f))
        return "\n\n".join(context)
</file>

<file path="app/api/__init__.py">
"""
API è·¯ç”±æ¨¡å—

æä¾›RESTful APIæ¥å£ï¼ŒåŒ…æ‹¬ï¼š
    - research: ç ”ç©¶ç›¸å…³APIæ¥å£
    - history: å†å²è®°å½•APIæ¥å£

æœ¬æ¨¡å—å°è£…äº†æ‰€æœ‰å¯¹å¤–æš´éœ²çš„APIè·¯ç”±ï¼Œ
é€šè¿‡FastAPIæ¡†æ¶å®ç°é«˜æ•ˆçš„ç½‘ç»œè¯·æ±‚å¤„ç†ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    from app.api import research, history

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from . import research, history

# æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å…¬å¼€çš„å­æ¨¡å—
__all__ = [
    "research",
    "history",
]
</file>

<file path="app/core/__init__.py">
"""
æ ¸å¿ƒé…ç½®æ¨¡å—

æä¾›ç³»ç»Ÿæ ¸å¿ƒé…ç½®å’ŒLLMè°ƒç”¨æ¥å£ã€‚

ä¸»è¦ç»„ä»¶:
    - simple_llm_call: é€šç”¨LLMè°ƒç”¨æ¥å£
        æ”¯æŒDeepSeekã€OpenAIã€Claudeã€Ollamaç­‰å¤šç§æ¨¡å‹
        é€šè¿‡LiteLLMæä¾›ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼

ä½¿ç”¨ç¤ºä¾‹:
    from app.core import simple_llm_call

    response = await simple_llm_call("Hello, world!")

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from .llm import simple_llm_call

__all__ = ["simple_llm_call"]
</file>

<file path="app/core/llm.py">
from litellm import completion
import os
from dotenv import load_dotenv

# åŠ è½½ .env ç¯å¢ƒå˜é‡
load_dotenv()

async def simple_llm_call(
    prompt: str, 
    model: str = "deepseek/deepseek-chat", # é»˜è®¤æ”¹ä¸º DeepSeek V3
    temperature: float = 0.7
) -> str:
    """
    é€šç”¨ LLM è°ƒç”¨æ¥å£ï¼Œæ”¯æŒ DeepSeek, OpenAI, Claude, Ollama ç­‰
    """
    
    # æ‰“å°å½“å‰ä½¿ç”¨çš„æ¨¡å‹ï¼Œæ–¹ä¾¿è°ƒè¯•
    print(f"ğŸ¤– [LLM Call] Model: {model}")

    try:
        # LiteLLM ä¼šè‡ªåŠ¨æ ¹æ® model å‰ç¼€è¯†åˆ«ä¾›åº”å•†
        # deepseek/deepseek-chat -> è‡ªåŠ¨æ˜ å°„åˆ° DeepSeek API
        # ollama/deepseek-r1 -> è‡ªåŠ¨æ˜ å°„åˆ°æœ¬åœ° Ollama
        
        response = completion(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            # å¦‚æœæ˜¯ DeepSeek APIï¼Œä¸éœ€è¦æ‰‹åŠ¨è®¾ base_urlï¼ŒLiteLLM å†…ç½®äº†æ”¯æŒ
            # å¦‚æœæ˜¯ Ollamaï¼ŒLiteLLM é»˜è®¤è¿æ¥ http://localhost:11434
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"âŒ [LLM Error] {model} failed: {str(e)}")
        return f"Error generation response with {model}. Details: {str(e)}"

# --- ä½¿ç”¨è¯´æ˜ ---
# 1. DeepSeek API: 
#    model="deepseek/deepseek-chat" (V3)
#    model="deepseek/deepseek-reasoner" (R1)
#
# 2. æœ¬åœ° DeepSeek (é€šè¿‡ Ollama):
#    model="ollama/deepseek-r1"
#
# 3. OpenAI:
#    model="gpt-4o"
</file>

<file path="app/modules/debate/mad_framework.py">
from typing import Dict, Literal
import asyncio

from app.core.config import settings
from app.core.utils import parse_json_safe
from app.core.llm import simple_llm_call
from app.modules.insight.prompts import ResearchPrompts

class DebateResult(Dict):
    winner: Literal["Affirmative", "Negative", "Uncertain"]
    conclusion: str
    reasoning: str

class MADFramework:
    """
    Multi-Agent Debate (MAD) æ¡†æ¶
    ç”¨äºè§£å†³äº‹å®å†²çªæˆ–é«˜æ­§ä¹‰é—®é¢˜
    """
    
    @staticmethod
    async def conduct_debate(topic: str, context: str) -> DebateResult:
        """
        æ‰§è¡Œä¸€è½®æ ‡å‡†çš„è¾©è®ºï¼šæ­£æ–¹ vs åæ–¹ -> æ³•å®˜è£å†³
        """
        print(f"âš–ï¸ [MAD] Starting debate on: {topic}")
        
        # 1. å¹¶è¡Œç”ŸæˆåŒæ–¹è¾©è¯ (Parallel Generation)
        # ä½¿ç”¨ Reasoning æ¨¡å‹ä»¥ä¿è¯é€»è¾‘æ€§
        task_affirmative = simple_llm_call(
            ResearchPrompts.debate_argument(topic, "æ­£æ–¹ (æ”¯æŒ/è‚¯å®š)", context),
            model=settings.MODEL_REASONING
        )

        task_negative = simple_llm_call(
            ResearchPrompts.debate_argument(topic, "åæ–¹ (åå¯¹/æ€€ç–‘)", context),
            model=settings.MODEL_REASONING
        )
        
        # å¹¶å‘æ‰§è¡Œ
        arg_aff, arg_neg = await asyncio.gather(task_affirmative, task_negative)
        
        print(f"ğŸ—£ï¸ [MAD] Affirmative: {arg_aff[:50]}...")
        print(f"ğŸ—£ï¸ [MAD] Negative: {arg_neg[:50]}...")
        
        # 2. æ³•å®˜è£å†³ (Judge)
        judge_prompt = ResearchPrompts.debate_judgment(topic, arg_aff, arg_neg)
        judge_response = await simple_llm_call(judge_prompt, model=settings.MODEL_REASONING)

        result = parse_json_safe(judge_response)
        if result:
            print(f"âš–ï¸ [MAD] Judgment: {result.get('winner')} - {result.get('conclusion')[:50]}...")
            return result
        else:
            print(f"âš ï¸ MAD Judgment parsing failed")
            return {
                "winner": "Uncertain",
                "conclusion": "Debate failed to reach consensus.",
                "reasoning": "Failed to parse judge response"
            }
</file>

<file path="app/modules/insight/__init__.py">
"""
æ´å¯Ÿæ¨¡å— - æ´å¯Ÿç”Ÿæˆå’ŒPromptç®¡ç†

è´Ÿè´£ç”Ÿæˆå’Œç®¡ç†æ™ºèƒ½æ´å¯Ÿï¼Œä»¥åŠä¸ºLLMæä¾›ç»“æ„åŒ–çš„æç¤ºè¯æ¨¡æ¿ã€‚

æœ¬æ¨¡å—çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
    - è®¾è®¡å’Œç®¡ç†Promptæ¨¡æ¿
    - æ ¹æ®ä¸åŒåœºæ™¯ç”Ÿæˆå®šåˆ¶åŒ–æç¤ºè¯
    - ä¼˜åŒ–LLMè¾“å…¥ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºè´¨é‡
    - ç”Ÿæˆæ·±åº¦åˆ†æå’Œæ´å¯ŸæŠ¥å‘Š

å­æ¨¡å—:
    - prompts: Promptæ¨¡æ¿ç®¡ç†
        æä¾›å„ç§åœºæ™¯ä¸‹çš„æç¤ºè¯æ¨¡æ¿
        åŒ…æ‹¬ç ”ç©¶ã€åˆ†æã€æ€»ç»“ã€åˆ›ä½œç­‰å¤šç§ç±»å‹
        æ”¯æŒåŠ¨æ€æ¨¡æ¿å‚æ•°åŒ–å’Œæ¨¡æ¿é“¾å¼ç»„åˆ

ä¸»è¦åŠŸèƒ½:
    1. æ™ºèƒ½Promptæ¨¡æ¿åº“
        - ç ”ç©¶ç±»æ¨¡æ¿ï¼šæ·±åº¦ç ”ç©¶ã€å¯¹æ¯”åˆ†æ
        - æ€»ç»“ç±»æ¨¡æ¿ï¼šæ‘˜è¦ç”Ÿæˆã€è¦ç‚¹æå–
        - åˆ›ä½œç±»æ¨¡æ¿ï¼šå†…å®¹åˆ›ä½œã€åˆ›æ„ç”Ÿæˆ
        - åˆ†æç±»æ¨¡æ¿ï¼šæ•°æ®åˆ†æã€è¶‹åŠ¿æ´å¯Ÿ

    2. åŠ¨æ€æ¨¡æ¿ç”Ÿæˆ
        - æ ¹æ®è¾“å…¥å‚æ•°ç”Ÿæˆå®šåˆ¶åŒ–æç¤ºè¯
        - æ”¯æŒæ¨¡æ¿åµŒå¥—å’Œç»„åˆ
        - æ™ºèƒ½å‚æ•°å¡«å……å’ŒéªŒè¯

    3. æç¤ºè¯ä¼˜åŒ–
        - è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯ç»“æ„
        - æä¾›æç¤ºè¯è´¨é‡è¯„ä¼°
        - æ”¯æŒA/Bæµ‹è¯•å’Œè¿­ä»£æ”¹è¿›

    4. æ´å¯Ÿç”Ÿæˆ
        - åŸºäºæ”¶é›†çš„æ•°æ®ç”Ÿæˆæ·±åº¦æ´å¯Ÿ
        - æä¾›å¤šç»´åº¦åˆ†æç»“æœ
        - ç”Ÿæˆå¯è§£é‡Šçš„åˆ†ææŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹:
    from app.modules.insight import prompts

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from . import prompts

# æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å…¬å¼€çš„å­æ¨¡å—
__all__ = [
    "prompts",
]
</file>

<file path="app/modules/knowledge/__init__.py">
from . import file_store
__all__ = ["file_store"]
</file>

<file path="app/modules/orchestrator/__init__.py">
"""
ç¼–æ’å™¨æ¨¡å— - å·¥ä½œæµç¼–æ’å™¨

ä½¿ç”¨LangGraphå®ç°çŠ¶æ€æœºå’Œå·¥ä½œæµç¼–æ’ã€‚

æœ¬æ¨¡å—è´Ÿè´£ï¼š
    - å®šä¹‰å’Œç®¡ç†å¤æ‚çš„å·¥ä½œæµçŠ¶æ€
    - å®ç°ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»å’Œè°ƒåº¦
    - åè°ƒå„ä¸ªæ¨¡å—ä¹‹é—´çš„äº¤äº’
    - æä¾›å¯æ‰©å±•çš„çŠ¶æ€è½¬æ¢é€»è¾‘

å­æ¨¡å—:
    - graph: å›¾ç»“æ„å’Œå·¥ä½œæµå®šä¹‰
        åŒ…å«LangGraphèŠ‚ç‚¹å’Œè¾¹çš„å®šä¹‰

    - state: çŠ¶æ€ç®¡ç†
        å®šä¹‰å…±äº«çŠ¶æ€ç»“æ„å’ŒçŠ¶æ€è½¬æ¢é€»è¾‘

å·¥ä½œæµç¨‹:
    1. åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
    2. é€šè¿‡graphå®šä¹‰æ‰§è¡Œè·¯å¾„
    3. ä½¿ç”¨stateè·Ÿè¸ªå’Œç®¡ç†çŠ¶æ€å˜åŒ–
    4. åè°ƒå„æ¨¡å—æŒ‰åºæ‰§è¡Œ

ä½¿ç”¨ç¤ºä¾‹:
    from app.modules.orchestrator import graph, state

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from . import graph, state

# çš„å­æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å…¬å¼€æ¨¡å—
__all__ = [
    "graph",
    "state",
]
</file>

<file path="app/modules/orchestrator/dag.py">
# app/modules/orchestrator/dag.py
from typing import List, Dict, Optional
from enum import Enum
from pydantic import BaseModel, Field
from datetime import datetime

class TaskStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class ResearchTask(BaseModel):
    id: str
    description: str
    dependencies: List[str] = Field(default_factory=list)
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[str] = None
    error: Optional[str] = None
    created_at: datetime = Field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    retry_count: int = 0
    
    # ğŸŸ¢ æ–°å¢ï¼šå…³è”çš„å¤§çº²ç« èŠ‚ (ç”¨äºè¿½è¸ªä»»åŠ¡å±äºå“ªä¸ªéƒ¨åˆ†)
    related_section: Optional[str] = None 

class DAGManager:
    def __init__(self, tasks: List[Dict] = None):
        self.tasks: Dict[str, ResearchTask] = {}
        if tasks:
            self.load_from_state(tasks)

    def load_from_state(self, task_list: List[Dict]):
        for t_data in task_list:
            # Pydantic ä¼šè‡ªåŠ¨å¤„ç† extra fieldsï¼Œä½†æœ€å¥½æ˜¾å¼å®šä¹‰
            task = ResearchTask(**t_data)
            self.tasks[task.id] = task

    def to_state(self) -> List[Dict]:
        return [task.model_dump(mode='json') for task in self.tasks.values()]

    def add_task(self, id: str, description: str, dependencies: List[str] = None, related_section: str = None):
        if id in self.tasks:
            if self.tasks[id].status == TaskStatus.PENDING:
                 self.tasks[id].description = description
                 self.tasks[id].dependencies = dependencies or []
                 # ğŸŸ¢ æ”¯æŒæ›´æ–°å…³è”ç« èŠ‚
                 if related_section:
                     self.tasks[id].related_section = related_section
            return
        
        deps = dependencies or []
        # ğŸŸ¢ ä¼ å…¥ related_section
        self.tasks[id] = ResearchTask(
            id=id, 
            description=description, 
            dependencies=deps,
            related_section=related_section
        )

    def get_ready_tasks(self) -> List[ResearchTask]:
        """è·å–å¯æ‰§è¡Œä»»åŠ¡"""
        ready_tasks = []
        for task in self.tasks.values():
            if task.status != TaskStatus.PENDING:
                continue
            
            dependencies_met = True
            for dep_id in task.dependencies:
                dep_task = self.tasks.get(dep_id)
                if not dep_task or dep_task.status not in [TaskStatus.COMPLETED]:
                    dependencies_met = False
                    if dep_task and dep_task.status in [TaskStatus.FAILED, TaskStatus.SKIPPED]:
                        self.skip_task(task.id, reason=f"Dependency {dep_id} failed/skipped")
                    break
            
            if dependencies_met:
                ready_tasks.append(task)
        
        return ready_tasks

    def set_task_running(self, task_id: str):
        if task_id in self.tasks:
            self.tasks[task_id].status = TaskStatus.RUNNING

    def complete_task(self, task_id: str, result: str):
        if task_id in self.tasks:
            t = self.tasks[task_id]
            t.status = TaskStatus.COMPLETED
            t.result = result
            t.completed_at = datetime.now()

    def fail_task(self, task_id: str, error: str):
        if task_id in self.tasks:
            t = self.tasks[task_id]
            t.status = TaskStatus.FAILED
            t.error = error
            t.completed_at = datetime.now()
            print(f"âŒ [DAG] Task {task_id} FAILED: {error}")

    def skip_task(self, task_id: str, reason: str):
        if task_id in self.tasks:
            t = self.tasks[task_id]
            t.status = TaskStatus.SKIPPED
            t.result = f"SKIPPED: {reason}"
            t.completed_at = datetime.now()
            print(f"â­ï¸ [DAG] Task {task_id} SKIPPED: {reason}")

    def is_all_completed(self) -> bool:
        return all(t.status in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.SKIPPED] 
                   for t in self.tasks.values())
</file>

<file path="app/modules/perception/__init__.py">
"""
æ„ŸçŸ¥æ¨¡å— - ä¿¡æ¯æ„ŸçŸ¥å’Œæ”¶é›†

è´Ÿè´£ä¿¡æ¯çš„æ”¶é›†ã€æ„ŸçŸ¥å’Œåˆæ­¥å¤„ç†ã€‚

æœ¬æ¨¡å—æä¾›å¤šç§ä¿¡æ¯æ”¶é›†èƒ½åŠ›ï¼š
    - ä»äº’è”ç½‘æŠ“å–ç½‘é¡µå†…å®¹
    - é€šè¿‡æœç´¢å¼•æ“è·å–ç›¸å…³ä¿¡æ¯
    - è§£æå’Œæå–å…³é”®ä¿¡æ¯
    - å¯¹æ”¶é›†çš„æ•°æ®è¿›è¡Œé¢„å¤„ç†

å­æ¨¡å—:
    - crawler: ç½‘é¡µçˆ¬è™«
        æä¾›æ™ºèƒ½ç½‘é¡µæŠ“å–èƒ½åŠ›
        æ”¯æŒåŠ¨æ€å†…å®¹åŠ è½½å’Œåçˆ¬è™«ç­–ç•¥

    - search: æœç´¢å¼•æ“
        é›†æˆå¤šç§æœç´¢å¼•æ“API
        æä¾›æ™ºèƒ½æœç´¢å’Œç»“æœç­›é€‰åŠŸèƒ½

ä¸»è¦åŠŸèƒ½:
    1. å¤šæºä¿¡æ¯æ”¶é›†
    2. å®æ—¶ç½‘é¡µå†…å®¹æŠ“å–
    3. æ™ºèƒ½æœç´¢å’Œç»“æœä¼˜åŒ–
    4. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
    5. æ”¯æŒå¤šç§æ•°æ®æ ¼å¼è¾“å‡º

ä½¿ç”¨ç¤ºä¾‹:
    from app.modules.perception import crawler, search

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from . import crawler, search

# æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å…¬å¼€çš„å­æ¨¡å—
__all__ = [
    "crawler",
    "search",
]
</file>

<file path="app/modules/utils/file_utils.py">
# app/modules/utils/file_utils.py
import os
import re
from datetime import datetime
from app.core.config import settings

def save_markdown_report(topic: str, content: str) -> str:
    """
    ç‹¬ç«‹å·¥å…·ï¼šå°† Markdown æŠ¥å‘Šä¿å­˜åˆ°ç£ç›˜
    
    Args:
        topic: ç ”ç©¶ä¸»é¢˜ (ç”¨äºç”Ÿæˆæ–‡ä»¶å)
        content: æŠ¥å‘Šå†…å®¹
        
    Returns:
        saved_path: ä¿å­˜çš„æ–‡ä»¶ç»å¯¹è·¯å¾„ (å¦‚æœæœªå¼€å¯æˆ–å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²)
    """
    # 1. æ£€æŸ¥é…ç½®å¼€å…³
    if not settings.SAVE_REPORT_TO_FILE:
        return ""

    try:
        # 2. ç¡®ä¿ç›®å½•å­˜åœ¨ (åŒé‡ä¿é™©)
        output_dir = settings.REPORT_OUTPUT_DIR
        os.makedirs(output_dir, exist_ok=True)

        # 3. æ¸…æ´—æ–‡ä»¶å (ç§»é™¤éæ³•å­—ç¬¦ï¼Œå°†ç©ºæ ¼è½¬ä¸ºä¸‹åˆ’çº¿ï¼Œé™åˆ¶é•¿åº¦)
        safe_topic = re.sub(r'[\\/*?:"<>|]', "", topic)
        safe_topic = safe_topic.strip().replace(" ", "_")[:50]
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{safe_topic}_{timestamp}.md"
        filepath = os.path.join(output_dir, filename)

        # 4. å†™å…¥æ–‡ä»¶
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)
            
        print(f"ğŸ’¾ [System] Report auto-saved to: {filepath}")
        return filepath

    except Exception as e:
        print(f"âš ï¸ [System] Failed to save report file: {e}")
        return ""
</file>

<file path="app/modules/verification/verification_agent.py">
# app/modules/verification/verification_agent.py

from typing import List, Dict, Literal
from pydantic import BaseModel
import json
import asyncio

from langchain_text_splitters import RecursiveCharacterTextSplitter

from app.core.config import settings
from app.core.utils import parse_json_safe
from app.core.llm import simple_llm_call
from app.modules.perception.search import search_generic as search_tool
from app.modules.insight.prompts import ResearchPrompts
# ğŸŸ¢ å¼•å…¥è¾©è®ºæ¡†æ¶
from app.modules.debate.mad_framework import MADFramework

class FactClaim(BaseModel):
    original_text: str
    claim: str
    verification_status: Literal["Verified", "Disputed", "Unconfirmed"] = "Unconfirmed"
    explanation: str = ""
    source_url: str = ""

class VerificationAgent:
    """
    [éªŒè¯æ™ºèƒ½ä½“ V3]
    é›†æˆ MAD (å¤šæ™ºèƒ½ä½“è¾©è®º) çš„ç»ˆæéªŒè¯ç³»ç»Ÿ
    èƒ½åŠ›ï¼šåˆ†å—æå– -> ç‹¬ç«‹éªŒè¯ -> äº‰è®®è‡ªåŠ¨è¾©è®º
    """
    
    @staticmethod
    async def extract_claims(text: str) -> List[FactClaim]:
        """ç¬¬ä¸€æ­¥ï¼šæå–å…³é”®äº‹å®æ–­è¨€ (Map-Reduce æ¨¡å¼)"""
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=4000,
            chunk_overlap=500,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", " ", ""]
        )
        chunks = splitter.split_text(text)
        
        print(f"ğŸ›¡ï¸ [Verification] Split text into {len(chunks)} chunks for extraction.")
        
        async def process_chunk(chunk_text: str) -> List[dict]:
            prompt = ResearchPrompts.verification_claims_extraction(chunk_text)
            response = await simple_llm_call(prompt, model=settings.MODEL_CHAT)
            result = parse_json_safe(response)
            return result if isinstance(result, list) else []

        results_list = await asyncio.gather(*[process_chunk(chunk) for chunk in chunks])
        
        unique_claims = {}
        for batch in results_list:
            if not isinstance(batch, list): continue
            for item in batch:
                claim_text = item.get("claim", "").strip()
                if not claim_text: continue
                if claim_text not in unique_claims:
                    try:
                        unique_claims[claim_text] = FactClaim(**item)
                    except: pass
        
        final_claims = list(unique_claims.values())
        print(f"ğŸ›¡ï¸ [Verification] Extracted {len(final_claims)} unique claims.")
        return final_claims

    @staticmethod
    async def verify_claim(claim: FactClaim) -> FactClaim:
        """
        ç¬¬äºŒæ­¥ï¼šç‹¬ç«‹æœç´¢éªŒè¯ + ğŸŸ¢ è‡ªåŠ¨è¾©è®ºå‡çº§
        """
        print(f"ğŸ” [Verification] Checking: {claim.claim}")
        
        # 1. è·å–ä¸Šä¸‹æ–‡
        try:
            results = await search_tool(f"verify {claim.claim}", num_results=3)
            context = "\n".join([r["snippet"] for r in results]) if results else "No search results found."
        except Exception as e:
            print(f"âš ï¸ Search failed: {e}")
            context = "Search failed."
        
        # 2. åˆå§‹ LLM åˆ¤å®š
        prompt = ResearchPrompts.verification_claim_check(claim.claim, context)
        response = await simple_llm_call(prompt, model=settings.MODEL_REASONING)

        data = parse_json_safe(response)
        if data:
            initial_status = data.get("status", "Unconfirmed")
            claim.explanation = data.get("explanation", "No explanation.")
            if results:
                claim.source_url = results[0]["url"]

            # ğŸŸ¢ 3. MAD è‡ªåŠ¨å‡çº§æœºåˆ¶ (Auto-Escalation)
            # å¦‚æœåˆå§‹åˆ¤å®šæœ‰äº‰è®®ï¼Œå¯åŠ¨è¾©è®ºæ¡†æ¶è¿›è¡Œæ·±ç©¶
            if initial_status == "Disputed":
                print(f"ğŸš¨ [Verification] Dispute detected! Escalating to MAD protocol for: {claim.claim}")

                # å¯åŠ¨è¾©è®º
                debate_result = await MADFramework.conduct_debate(claim.claim, context)

                # æ ¹æ®è¾©è®ºç»“æœæ›´æ–°çŠ¶æ€
                # å¦‚æœæ­£æ–¹(Affirmative)èµ¢äº†ï¼Œè¯´æ˜åŸæ–­è¨€å…¶å®æ˜¯æˆç«‹çš„ï¼Œä¹‹å‰å¯èƒ½è¯¯åˆ¤
                if debate_result["winner"] == "Affirmative":
                    claim.verification_status = "Verified"
                    claim.explanation = f"[MAD Overrule] {debate_result['conclusion']}"
                    print(f"âœ… [MAD] Overruled dispute -> Verified")

                # å¦‚æœåæ–¹(Negative)èµ¢äº†ï¼Œç¡®è®¤æ˜¯é”™è¯¯çš„
                elif debate_result["winner"] == "Negative":
                    claim.verification_status = "Disputed"
                    claim.explanation = f"[MAD Confirmed Dispute] {debate_result['conclusion']}"
                    print(f"âŒ [MAD] Confirmed dispute.")

                else:
                    claim.verification_status = "Unconfirmed"
                    claim.explanation = f"[MAD Uncertain] {debate_result['conclusion']}"

            else:
                # æ²¡æœ‰äº‰è®®ï¼Œç›´æ¥é‡‡çº³åˆå§‹ç»“æœ
                claim.verification_status = initial_status
        else:
            print(f"âš ï¸ Verification logic failed: Failed to parse response")
            claim.verification_status = "Unconfirmed"
            claim.explanation = "è§£æéªŒè¯å“åº”å¤±è´¥"

        return claim

    @classmethod
    async def verify_report(cls, draft: str) -> str:
        """ä¸»å…¥å£"""
        # 1. æå–
        claims = await cls.extract_claims(draft)
        if not claims:
            # æ·»åŠ æœªéªŒè¯è­¦å‘Šè¯´æ˜ï¼Œè€Œéé™é»˜è·³è¿‡
            warning = "\n\n---\n> âš ï¸ **æ³¨æ„**ï¼šç³»ç»Ÿæœªèƒ½ä»æ–‡æœ¬ä¸­æå–å‡ºå¯éªŒè¯çš„ç‹¬ç«‹äº‹å®æ–­è¨€ï¼Œæœ¬æŠ¥å‘Šæœªç»è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥ã€‚"
            return draft + warning

        # 2. éªŒè¯ (å¹¶å‘æ§åˆ¶)
        sem = asyncio.Semaphore(5)
        async def sem_task(c):
            async with sem:
                return await cls.verify_claim(c)

        verified_claims = await asyncio.gather(*[sem_task(c) for c in claims])
        
        # 3. æŠ¥å‘Šç”Ÿæˆ
        report_suffix = "\n\n---\n### ğŸ›¡ï¸ äº‹å®æ ¸æŸ¥æŠ¥å‘Š (Automated Verification)\n"
        has_dispute = False
        
        for c in verified_claims:
            icon = "âœ…"
            if c.verification_status == "Disputed":
                icon = "âŒ"
                has_dispute = True
            elif c.verification_status == "Unconfirmed":
                icon = "âš ï¸"
            
            # å¦‚æœç»è¿‡äº† MADï¼ŒåŠ ä¸Šæ ‡è®°
            mad_tag = "âš–ï¸" if "[MAD" in c.explanation else ""
            source_link = f"([Source]({c.source_url}))" if c.source_url else ""
            
            report_suffix += f"- {icon} {mad_tag} **{c.verification_status}**: {c.claim}\n  *è¯´æ˜: {c.explanation}* {source_link}\n"
            
        final_draft = draft
        if has_dispute:
            warning = "> âš ï¸ **è­¦å‘Šï¼šæœ¬æŠ¥å‘ŠåŒ…å«éƒ¨åˆ†å­˜åœ¨äº‰è®®çš„äº‹å®ï¼Œç³»ç»Ÿå·²ä»‹å…¥å¤šæ™ºèƒ½ä½“è¾©è®º(MAD)è¿›è¡Œè£å†³ï¼Œè¯¦æƒ…è§æ–‡æœ«ã€‚**\n\n"
            final_draft = warning + final_draft + report_suffix
        else:
            final_draft = final_draft + report_suffix
            
        return final_draft
</file>

<file path="app/modules/__init__.py">
"""
æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

åŒ…å«äº”å¤§æ ¸å¿ƒæ¨¡å—ï¼š
    - orchestrator: å·¥ä½œæµç¼–æ’å™¨
        ä½¿ç”¨LangGraphå®ç°çŠ¶æ€æœºå’Œå·¥ä½œæµç¼–æ’
        è´Ÿè´£ä»»åŠ¡è°ƒåº¦ã€æµç¨‹æ§åˆ¶å’Œæ¨¡å—åè°ƒ

    - perception: ä¿¡æ¯æ„ŸçŸ¥æ¨¡å—
        è´Ÿè´£ä¿¡æ¯æ”¶é›†å’Œæ„ŸçŸ¥
        åŒ…æ‹¬ç½‘é¡µæŠ“å–(crawler)å’Œæœç´¢å¼•æ“(search)èƒ½åŠ›

    - knowledge: çŸ¥è¯†å¼•æ“
        è´Ÿè´£æ•°æ®çš„å­˜å‚¨ã€ç´¢å¼•å’Œæ£€ç´¢
        åŒ…æ‹¬å‘é‡æ•°æ®åº“(LanceDB)å’Œå…³ç³»å‹æ•°æ®åº“(SQLModel)

    - insight: æ´å¯Ÿæ¨¡å—
        è´Ÿè´£ç”Ÿæˆå’Œç®¡ç†Promptæ¨¡æ¿
        ä¸ºLLMæä¾›ç»“æ„åŒ–çš„æç¤ºè¯

è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œå®ç°å®Œæ•´çš„AIé©±åŠ¨ç ”ç©¶æµç¨‹ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    from app.modules import (
        orchestrator,
        perception,
        knowledge,
        insight
    )

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
"""

from . import (
    orchestrator,
    perception,
    knowledge,
    insight
)

# æ˜ç¡®åˆ—å‡ºæ‰€æœ‰å…¬å¼€çš„æ ¸å¿ƒæ¨¡å—
__all__ = [
    "orchestrator",
    "perception",
    "knowledge",
    "insight",
]
</file>

<file path="app/__init__.py">
"""
Deep Research Backend - æ ¸å¿ƒåº”ç”¨åŒ…

è¿™æ˜¯ä¸€ä¸ªåŸºäºAIçš„æ·±åº¦ç ”ç©¶ç³»ç»Ÿï¼Œæä¾›æ™ºèƒ½ä¿¡æ¯æ”¶é›†ã€åˆ†æå’Œæ´å¯Ÿèƒ½åŠ›ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼šå·¥ä½œæµç¼–æ’ã€ä¿¡æ¯æ„ŸçŸ¥ã€çŸ¥è¯†ç®¡ç†å’Œæ´å¯Ÿç”Ÿæˆã€‚

ä¸»è¦æ¨¡å—:
    - api: APIè·¯ç”±å’Œæ¥å£
    - modules: æ ¸å¿ƒåŠŸèƒ½æ¨¡å—é›†åˆ
        - orchestrator: å·¥ä½œæµç¼–æ’å™¨
        - perception: ä¿¡æ¯æ„ŸçŸ¥å’Œæ”¶é›†
        - knowledge: çŸ¥è¯†å­˜å‚¨å’Œæ£€ç´¢
        - insight: æ´å¯Ÿç”Ÿæˆ

ä½¿ç”¨è¯´æ˜:
    # å¯¼å…¥APIæ¨¡å—
    from app.api import research, history

    # å¯¼å…¥æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
    from app.modules import orchestrator, perception, knowledge, insight

    # å¯¼å…¥LLMè°ƒç”¨æ¥å£
    from app.core import simple_llm_call

ä½œè€…: ApexBridge Team
ç‰ˆæœ¬: 1.0.0
è®¸å¯è¯: MIT
"""

__version__ = "1.0.0"
__author__ = "ApexBridge Team"
__email__ = "team@apexbridge.ai"
__license__ = "MIT"
__description__ = "åŸºäºAIçš„æ·±åº¦ç ”ç©¶ç³»ç»Ÿ"


__all__ = [
    "__version__",
    "__author__",
    "__email__",
    "__license__",
    "__description__",
]
</file>

<file path="test/test_runner.py">
import httpx
import json
import os

# é…ç½®ç›®æ ‡
API_URL = "http://localhost:23800/api/stream"  # æ³¨æ„ï¼šè·¯ç”±å‰ç¼€æ˜¯ /api
TOPIC = "NexaAIå’ŒAutoGLMç»“åˆåœ¨ç§»åŠ¨ç«¯è½åœ°å¯èƒ½æ€§"             # æ‚¨æƒ³æœçš„é¢˜ç›®

def run_test():
    print(f"ğŸš€ [Test] Starting Deep Research on: '{TOPIC}'")
    print("-" * 60)

    try:
        # å‘èµ·æµå¼è¯·æ±‚ (è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºæ·±åº¦ç ”ç©¶å¾ˆè€—æ—¶)
        with httpx.stream("GET", API_URL, params={"topic": TOPIC}, timeout=600.0) as response:
            if response.status_code != 200:
                print(f"âŒ API Error: {response.status_code}")
                print(response.read().decode())
                return

            for line in response.iter_lines():
                if not line: continue
                
                # SSE æ ¼å¼é€šå¸¸æ˜¯ä»¥ "data: " å¼€å¤´
                if line.startswith("data: "):
                    data_str = line[6:] # å»æ‰ "data: " å‰ç¼€
                    
                    if data_str == "[DONE]" or data_str == "DONE":
                        print("\nâœ… Research Completed!")
                        break
                    
                    try:
                        # è§£æå¤–å±‚ JSON
                        payload = json.loads(data_str)
                        
                        # å¤„ç†é”™è¯¯
                        if payload.get("event") == "error":
                            err_data = json.loads(payload["data"])
                            print(f"\nâŒ SERVER ERROR: {err_data.get('error')}")
                            break

                        # å¤„ç†æ­£å¸¸æ›´æ–°
                        if payload.get("event") == "update":
                            # è§£æå†…å±‚æ•°æ® (å› ä¸º data å­—æ®µæœ¬èº«ä¹Ÿæ˜¯ä¸ª JSON å­—ç¬¦ä¸²)
                            inner_data = json.loads(payload["data"])
                            step = inner_data.get("step")
                            content = inner_data.get("data")
                            
                            # --- æ‰“å°ç¾åŒ–æ—¥å¿— ---
                            if step == "planner":
                                plan = content.get("plan", [])
                                print(f"\nğŸ§  [Planner] Generated Plan ({len(plan)} tasks):")
                                for t in plan:
                                    status = t['status']
                                    icon = "âœ…" if status == 'completed' else "â³"
                                    if status == 'running': icon = "â–¶ï¸"
                                    print(f"   {icon} {t['description']}")
                                    
                            elif step == "searcher":
                                results = content.get("web_results", [])
                                if results:
                                    print(f"\nğŸŒ [Searcher] Scraped {len(results)} pages.")

                            elif step == "analyst":
                                print(f"\nğŸ“ [Analyst] Drafting Report...")

                            elif step == "critic":
                                logs = content.get("reflection_logs", [])
                                if logs:
                                    latest = logs[-1]
                                    print(f"\nâš–ï¸ [Critic] Score: {latest['score']}/10 -> {latest['adjustment']}")

                            elif step == "publisher":
                                print(f"\nğŸ“° [Publisher] Final Report Generated!")
                                # è¿™é‡Œåªæ˜¯ä¸ºäº†æç¤ºï¼Œå®é™…æ–‡ä»¶å·²ç»ç”±åç«¯ä¿å­˜äº†

                    except json.JSONDecodeError:
                        pass
                        
    except Exception as e:
        print(f"\nâŒ Connection Failed: {e}")
        print("Tip: Make sure the server is running (python main.py)")

if __name__ == "__main__":
    run_test()
</file>

<file path=".env.example">
# .env Template
# Copy this file to .env and fill in your values
# Comments use "#", don't add spaces around "="

# ============================================
# Service Configuration
# ============================================
API_HOST=0.0.0.0
API_PORT=23800

# ============================================
# Data Storage Paths
# ============================================
LANCEDB_PATH=./data/lancedb
CHECKPOINT_DB_PATH=./data/checkpoints.db

# ============================================
# Report Output Configuration
# ============================================
# Whether to save final report as Markdown file
SAVE_REPORT_TO_FILE=true
# Report output directory
REPORT_OUTPUT_DIR=./outputs

# ============================================
# Search Configuration
# ============================================
# Search provider: "tavily" or "searxng"
SEARCH_PROVIDER=tavily

# SearXNG Configuration (only used when SEARCH_PROVIDER=searxng)
SEARXNG_BASE_URL=http://localhost:8888/search

# Tavily Configuration (supports multiple API keys with round-robin)
# Separate multiple keys with commas: TAVILY_API_KEYS=key1,key2
# Get API keys at: https://tavily.com/
TAVILY_API_KEYS=your_tavily_api_keys_here

# ============================================
# LLM API Configuration
# ============================================
# DeepSeek API Key (recommended)
# Get yours at: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenAI API Key (optional)
# OPENAI_API_KEY=

# Anthropic (Claude) Custom Base URL (optional)
# ANTHROPIC_API_BASE="https://api.openai.com/v1"
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ============================================
# Tiered Model Strategy
# ============================================
# Choose models based on task complexity

# [Planner/Reasoning]: DAG generation, task decomposition, complex reasoning
MODEL_PLANNER=anthropic/MiniMax-M2.1

# [Writer]: Long-form generation, report writing
MODEL_WRITER=anthropic/MiniMax-M2.1

# [Critic/Judge]: Reflection scoring, MAD debateè£å†³
MODEL_CRITIC=anthropic/MiniMax-M2.1

# [Fast Task]: Crawler cleaning, simple info extraction
MODEL_FAST=anthropic/MiniMax-M2.1

# [Long Context]: Reading large amounts of search results at once
MODEL_LONG=anthropic/MiniMax-M2.1

# [General Purpose]: Fallback default model
MODEL_SMART=anthropic/MiniMax-M2.1

# ============================================
# Runtime Controls
# ============================================
# LangGraph max recursion limit (prevent infinite loops)
MAX_RECURSION_LIMIT=100
# Global timeout in seconds
GLOBAL_TIMEOUT_SEC=600
# Search depth
MAX_SEARCH_RESULTS=5

# ============================================
# Embedding Model Configuration
# ============================================
# Embedding model for vector retrieval

# Options:
# 1. Local Ollama:
#    - ollama/nomic-embed-text (768 dim)
#    - ollama/llama3.2:3b (3072 dim)
# 2. OpenAI:
#    - openai/text-embedding-3-small (1536 dim)
#    - openai/text-embedding-3-large (3072 dim)
EMBEDDING_MODEL=ollama/nomic-embed-text
# Vector dimension (must match EMBEDDING_MODEL)
EMBEDDING_DIMENSION=768

# ============================================
# Optional: LangSmith Tracing (for debugging)
# ============================================
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=apexbridge-research
</file>

<file path=".repomixignore">
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/
**/*.md
research/
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 ApexBridge Deep Research System Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="main.py">
# main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api.research import router as research_router
import uvicorn
from app.core.config import settings

app = FastAPI(title="Deep Research Backend")

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(research_router, prefix="/api")

if __name__ == "__main__":
    print(f"ğŸš€ Starting server on {settings.API_HOST}:{settings.API_PORT}")
    uvicorn.run(
        "main:app", 
        host=settings.API_HOST, 
        port=settings.API_PORT, 
        reload=True
    )
</file>

<file path="repomix.config.json">
{
  "$schema": "https://repomix.com/schemas/latest/schema.json",
  "input": {
    "maxFileSize": 52428800
  },
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "parsableStyle": false,
    "fileSummary": true,
    "directoryStructure": true,
    "files": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "compress": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "truncateBase64": false,
    "copyToClipboard": false,
    "includeFullDirectoryStructure": false,
    "tokenCountTree": false,
    "git": {
      "sortByChanges": true,
      "sortByChangesMaxCommits": 100,
      "includeDiffs": false,
      "includeLogs": false,
      "includeLogsCount": 50
    }
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDotIgnore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
</file>

<file path="app/modules/orchestrator/state.py">
# app/modules/orchestrator/state.py
from typing import List, TypedDict, Annotated, Optional, Literal
import operator

# --- åŸºç¡€æ•°æ®æ¨¡å‹ ---

class ResearchStep(TypedDict):
    id: str
    description: str
    status: Literal["pending", "running", "completed", "failed", "skipped"]
    dependencies: List[str]
    result: Optional[str]
    # ğŸŸ¢ æ–°å¢ï¼šå…³è”çš„å¤§çº²ç« èŠ‚ (ç”¨äºè¿½è¸ªè¿›åº¦)
    related_section: Optional[str]

class ReflectionLog(TypedDict):
    step_name: str
    critique: str
    score: float
    adjustment: str

# --- æ ¸å¿ƒçŠ¶æ€å®šä¹‰ ---

class ResearchState(TypedDict):
    """
    Deep Research V3 æ ¸å¿ƒçŠ¶æ€
    """
    # --- åŸºç¡€ä¿¡æ¯ ---
    task_id: str
    task: str
    
    # å¯¹é½ä¸ç»“æ„åŒ–å±‚
    clarified_intent: str
    needs_clarification: bool
    clarification_history: List[str]
    
    outline: List[str]
    
    # --- æ‰§è¡Œå±‚ ---
    plan: List[ResearchStep]
    
    # ğŸŸ¢ [æ ¸å¿ƒä¿®å¤] è¡¥ä¸Šè¿™ä¸ªç¼ºå¤±çš„å­—æ®µï¼
    search_queries: List[str] 
    
    # --- è®°å¿†ä¸è¾“å‡º ---
    knowledge_stats: Annotated[List[str], operator.add] 
    reflection_logs: Annotated[List[ReflectionLog], operator.add]
    iteration_count: int
    max_iterations: int
    
    # --- ä¸­é—´å˜é‡ ---
    topic: str
    draft_report: str
    final_report: str
</file>

<file path="app/modules/perception/crawler.py">
# app/modules/perception/crawler.py
import asyncio
import httpx
import fitz  # PyMuPDF
import numpy as np
import cv2
import logging
from crawl4ai import AsyncWebCrawler
from typing import List, Dict

# å°è¯•å¯¼å…¥ PaddleOCR
PADDLE_AVAILABLE = False
try:
    from paddleocr import PaddleOCR
    PADDLE_AVAILABLE = True
except ImportError:
    print("âš ï¸ PaddleOCR not installed. Scanning features disabled.")

# å…¨å±€ OCR å¼•æ“å•ä¾‹ (æ‡’åŠ è½½)
_ocr_engine = None

def get_ocr_engine():
    global _ocr_engine
    if _ocr_engine is None and PADDLE_AVAILABLE:
        print("ğŸ‘ï¸ [System] Loading PaddleOCR Model (This may take time)...")
        # use_angle_cls=True è‡ªåŠ¨çº æ­£æ–¹å‘, lang="ch" æ”¯æŒä¸­è‹±æ–‡
        _ocr_engine = PaddleOCR(use_angle_cls=True, lang="ch", show_log=False)
    return _ocr_engine

def process_pdf_sync(pdf_bytes: bytes, url: str) -> str:
    """
    [åŒæ­¥å‡½æ•°] PDF å¤„ç†æ ¸å¿ƒé€»è¾‘ï¼šPyMuPDF + PaddleOCR æ··åˆç­–ç•¥
    å°†åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œï¼Œé¿å…é˜»å¡ Async äº‹ä»¶å¾ªç¯ã€‚
    """
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    except Exception as e:
        print(f"âŒ [PDF] Failed to open: {e}")
        return ""

    full_text = []
    ocr = get_ocr_engine()
    total_pages = len(doc)
    
    print(f"ğŸ“„ [PDF] Processing {total_pages} pages from {url}...")

    # é™åˆ¶å¤„ç†é¡µæ•°ï¼Œé˜²æ­¢å‡ ç™¾é¡µçš„è´¢æŠ¥æŠŠ OCR è·‘æ­» (æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œæ¯”å¦‚å‰20é¡µæ ¸å¿ƒå†…å®¹)
    # å¦‚æœæ‚¨çœŸçš„"ä¸åœ¨ä¹æ—¶é—´"ï¼Œå¯ä»¥æŠŠè¿™ä¸ªé™åˆ¶å»æ‰æˆ–è°ƒå¤§
    MAX_OCR_PAGES = 15 

    for i, page in enumerate(doc):
        # 1. å°è¯•ç›´æ¥æå–æ–‡æœ¬ (æå¿«)
        text = page.get_text()
        
        # 2. å¯†åº¦æ£€æµ‹ï¼šå¦‚æœæ–‡å­—æå°‘ï¼Œåˆ¤å®šä¸ºæ‰«æä»¶/å›¾ç‰‡
        if len(text.strip()) < 50 and PADDLE_AVAILABLE:
            if i < MAX_OCR_PAGES:
                print(f"   ğŸ” [OCR] Page {i+1}/{total_pages} is image-based. Scanning...")
                try:
                    # æ¸²æŸ“ä¸ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡ (zoom=2) æå‡è¯†åˆ«ç‡
                    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                    
                    # è½¬æ¢ PyMuPDF(Pix) -> Numpy(OpenCV)
                    img_data = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)
                    
                    # é¢œè‰²ç©ºé—´è½¬æ¢
                    if pix.n == 4:
                        img_data = cv2.cvtColor(img_data, cv2.COLOR_RGBA2RGB)
                    elif pix.n == 3:
                        pass # RGB
                    else:
                        img_data = cv2.cvtColor(img_data, cv2.COLOR_GRAY2RGB)

                    # æ‰§è¡Œ OCR
                    result = ocr.ocr(img_data, cls=True)
                    
                    # è§£æç»“æœ
                    ocr_lines = []
                    if result and result[0]:
                        for line in result[0]:
                            # line ç»“æ„: [[box], (text, score)]
                            txt = line[1][0]
                            ocr_lines.append(txt)
                    
                    ocr_text = "\n".join(ocr_lines)
                    text = f"\n--- [Page {i+1} OCR Scan] ---\n{ocr_text}\n"
                    
                except Exception as e:
                    print(f"âš ï¸ [OCR] Failed on page {i+1}: {e}")
            else:
                text = "\n[OCR Skipped: Page limit reached]\n"
        
        full_text.append(text)
    
    return "\n\n".join(full_text)

async def extract_pdf_content(url: str) -> str:
    """ä¸‹è½½å¹¶è§£æ PDF"""
    print(f"â¬‡ï¸ [PDF] Downloading: {url}")
    try:
        async with httpx.AsyncClient(verify=False, follow_redirects=True, timeout=60.0) as client:
            response = await client.get(url)
            # å¤„ç†éƒ¨åˆ†æœåŠ¡å™¨è¿”å› 403 çš„æƒ…å†µï¼Œæ¨¡æ‹Ÿ UA
            if response.status_code != 200:
                response = await client.get(url, headers={"User-Agent": "Mozilla/5.0"})
            
            response.raise_for_status()
            
            # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ PDF
            if b"%PDF" not in response.content[:10]:
                return None 

            # ğŸŸ¢ å…³é”®ï¼šå°†ç¹é‡çš„ PDF å¤„ç†æ”¾å…¥çº¿ç¨‹æ± 
            return await asyncio.to_thread(process_pdf_sync, response.content, url)

    except Exception as e:
        print(f"âŒ [PDF] Download error {url}: {e}")
        return None

async def crawl_urls(urls: List[str]) -> List[Dict]:
    """æ™ºèƒ½æ··åˆçˆ¬è™«å…¥å£"""
    if not urls: return []

    print(f"ğŸ•·ï¸ [Smart Crawler] Processing {len(urls)} URLs...")
    
    results = []
    pdf_urls = [u for u in urls if u.lower().endswith(".pdf")]
    web_urls = [u for u in urls if not u.lower().endswith(".pdf")]
    
    # 1. å¤„ç† PDF (é™åˆ¶å¹¶å‘ï¼Œé˜²æ­¢ CPU çˆ†ç‚¸)
    if pdf_urls:
        print(f"ğŸ“„ Found {len(pdf_urls)} PDFs. Queueing OCR...")
        # ä¿¡å·é‡æ§åˆ¶åŒæ—¶è¿›è¡Œçš„ OCR ä»»åŠ¡æ•° (CPUå¯†é›†å‹)
        sem = asyncio.Semaphore(2) 
        
        async def safe_pdf_task(u):
            async with sem:
                content = await extract_pdf_content(u)
                if content:
                    return {"url": u, "content": content, "source": "pdf_document"}
                return None

        pdf_results = await asyncio.gather(*[safe_pdf_task(u) for u in pdf_urls])
        
        for i, res in enumerate(pdf_results):
            if res:
                results.append(res)
            else:
                # å‡å¦‚è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯ä¼ªè£…çš„ HTMLï¼Œä¸¢å› Web é˜Ÿåˆ—
                web_urls.append(pdf_urls[i])

    # 2. å¤„ç† Web é¡µé¢ (crawl4ai)
    if web_urls:
        print(f"ğŸŒ [Crawl4AI] Crawling {len(web_urls)} web pages...")
        async with AsyncWebCrawler(verbose=True) as crawler:
            async def process_web(url):
                # ç®€å•é‡è¯•
                for _ in range(2):
                    try:
                        res = await crawler.arun(
                            url=url, 
                            bypass_cache=True, 
                            word_count_threshold=50,
                            delay_before_return_html=1.0, # ç»™ JS ä¸€ç‚¹æ—¶é—´
                            timeout=30000
                        )
                        if res.success:
                            # é™åˆ¶å•é¡µé•¿åº¦ï¼Œé˜²æ­¢å•ä¸ªç½‘é¡µ 5MB æ–‡æœ¬æ’‘çˆ†å†…å­˜
                            return {"url": url, "content": res.markdown[:200000], "source": "web_page"}
                    except: pass
                return None
            
            web_results = await asyncio.gather(*[process_web(u) for u in web_urls])
            results.extend([r for r in web_results if r])

    return results
</file>

<file path="app/modules/perception/search.py">
# app/modules/perception/search.py
import asyncio
import functools
import random
from typing import List, Dict
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# ğŸŸ¢ å¼•å…¥æˆç†Ÿçš„å¼€æºåº“
import arxiv
from github import Github, Auth
import wikipedia

from app.core.config import settings

# --- 1. arXiv æœç´¢ (åŸºäº arxiv åº“) ---
def _sync_arxiv_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] arXiv æœç´¢é€»è¾‘"""
    print(f"ğŸ“š [arXiv] Searching: {query}...")
    try:
        # æ„é€ æœç´¢å®¢æˆ·ç«¯
        client = arxiv.Client()
        search = arxiv.Search(
            query=query,
            max_results=limit,
            sort_by=arxiv.SortCriterion.Relevance
        )
        
        results = []
        for r in client.results(search):
            results.append({
                "url": r.pdf_url, # ç›´æ¥ç»™ PDF é“¾æ¥ï¼Œé…åˆæˆ‘ä»¬çš„ PDF è§£æå™¨
                "title": f"[arXiv] {r.title}",
                "snippet": f"Published: {r.published.date()}\nAbstract: {r.summary[:500]}...",
                "source": "arxiv"
            })
        return results
    except Exception as e:
        print(f"âš ï¸ [arXiv] Error: {e}")
        return []

async def _search_arxiv(query: str, limit: int = 3) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_ARXIV: return []
    return await asyncio.to_thread(_sync_arxiv_search, query, limit)


# --- 2. GitHub æœç´¢ (åŸºäº PyGithub åº“) ---
def _sync_github_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] GitHub æœç´¢é€»è¾‘"""
    print(f"ğŸ’» [GitHub] Searching: {query}...")
    try:
        # é‰´æƒ (å¼ºçƒˆå»ºè®®é…ç½® Tokenï¼Œå¦åˆ™é™åˆ¶æä¸¥)
        auth = Auth.Token(settings.GITHUB_TOKEN) if settings.GITHUB_TOKEN else None
        g = Github(auth=auth)
        
        # æœç´¢ä»“åº“
        repos = g.search_repositories(query=query, sort="stars", order="desc")
        
        results = []
        # PyGithub çš„åˆ†é¡µæ˜¯æ‡’åŠ è½½çš„ï¼Œåªå–å‰ limit ä¸ª
        for i, repo in enumerate(repos):
            if i >= limit: break
            
            results.append({
                "url": repo.html_url,
                "title": f"[GitHub] {repo.full_name} ({repo.stargazers_count}â­)",
                "snippet": f"Language: {repo.language}\nDescription: {repo.description}\n(Readme will be crawled)",
                "source": "github"
            })
        
        g.close()
        return results
    except Exception as e:
        print(f"âš ï¸ [GitHub] Error: {e}")
        return []

async def _search_github(query: str, limit: int = 3) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_GITHUB: return []
    return await asyncio.to_thread(_sync_github_search, query, limit)


# --- 3. Wikipedia æœç´¢ (åŸºäº wikipedia åº“) ---
def _sync_wiki_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] Wiki æœç´¢é€»è¾‘"""
    print(f"ğŸ“– [Wiki] Searching: {query}...")
    try:
        # ä¼˜å…ˆå°è¯•ä¸­æ–‡ï¼Œè‹¥æ— ç»“æœå¯è€ƒè™‘å›é€€è‹±æ–‡ (æ­¤å¤„ç®€åŒ–ä¸ºä¸­æ–‡)
        wikipedia.set_lang("zh")
        
        # 1. æœç´¢è¯æ¡æ ‡é¢˜
        search_results = wikipedia.search(query, results=limit)
        if not search_results:
            # å›é€€åˆ°è‹±æ–‡
            wikipedia.set_lang("en")
            search_results = wikipedia.search(query, results=limit)
            
        final_results = []
        for title in search_results:
            try:
                # 2. è·å–è¯æ¡è¯¦æƒ…
                # auto_suggest=False é˜²æ­¢è‡ªåŠ¨çº é”™å¯¼è‡´æœåˆ°ä¸ç›¸å…³çš„
                page = wikipedia.page(title, auto_suggest=False)
                
                final_results.append({
                    "url": page.url,
                    "title": f"[Wiki] {page.title}",
                    "snippet": page.summary[:500] + "...",
                    "source": "wiki"
                })
            except wikipedia.DisambiguationError as e:
                # æ­§ä¹‰é¡µé¢ï¼Œå–ç¬¬ä¸€ä¸ªé€‰é¡¹é‡è¯•
                try:
                    page = wikipedia.page(e.options[0], auto_suggest=False)
                    final_results.append({
                        "url": page.url,
                        "title": f"[Wiki] {page.title}",
                        "snippet": page.summary[:500] + "...",
                        "source": "wiki"
                    })
                except: pass
            except wikipedia.PageError:
                pass # é¡µé¢ä¸å­˜åœ¨
                
        return final_results
    except Exception as e:
        print(f"âš ï¸ [Wiki] Error: {e}")
        return []

async def _search_wiki(query: str, limit: int = 2) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_WIKI: return []
    return await asyncio.to_thread(_sync_wiki_search, query, limit)


# --- 4. Web æœç´¢ (Tavily) - æ”¯æŒå¤š Key è½®è¯¢ ---
async def _search_web_tavily(query: str, limit: int) -> List[Dict]:
    from app.core.config import settings
    # éšæœºé€‰æ‹©ä¸€ä¸ª API Keyï¼Œå®ç°è´Ÿè½½å‡è¡¡
    api_key = random.choice(settings.TAVILY_API_KEYS) if settings.TAVILY_API_KEYS else None
    if not api_key: return []
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.post(
                "https://api.tavily.com/search",
                json={"api_key": api_key, "query": query, "max_results": limit, "search_depth": "basic"},
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            return [{
                "url": r["url"], 
                "title": r["title"], 
                "snippet": r["content"], 
                "source": "web"
            } for r in data.get("results", [])]
    except Exception as e:
        print(f"âš ï¸ [Web] Error: {e}")
        return []


# --- 5. èšåˆå…¥å£ ---
async def search_generic(query: str, num_results: int = 5) -> List[Dict[str, str]]:
    """
    [æ··åˆæœç´¢ V2] åŸºäºæˆç†Ÿ SDK çš„å¹¶è¡Œæœç´¢
    """
    print(f"ğŸ” [Hybrid Search] Dispatching: {query}...")
    
    # å®šä¹‰ä»»åŠ¡ï¼šåŒæ—¶è§¦å‘ 4 è·¯æœç´¢
    tasks = [
        _search_arxiv(query, limit=settings.Result_Count_Arxiv),
        _search_github(query, limit=settings.Result_Count_Github),
        _search_wiki(query, limit=settings.Result_Count_Wiki),
        _search_web_tavily(query, limit=settings.Result_Count_Web)
    ]
    
    # å¹¶å‘æ‰§è¡Œ (è€—æ—¶å–å†³äºæœ€æ…¢çš„é‚£ä¸ªï¼Œé€šå¸¸æ˜¯ Web æˆ– GitHub)
    results_list = await asyncio.gather(*tasks)
    
    # å±•å¹³ä¸å»é‡
    all_results = []
    seen_urls = set()
    
    for res_group in results_list:
        for r in res_group:
            if r['url'] not in seen_urls:
                seen_urls.add(r['url'])
                all_results.append(r)
            
    print(f"âœ… [Hybrid Search] Found {len(all_results)} total results")
    return all_results

# å…¼å®¹å¯¼å‡º
search_tool = search_generic
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be added to the global gitignore or merged into this project gitignore.  For a PyCharm
#  project, it is recommended to exclude .idea directory in version control.
.idea/

# VS Code
.vscode/
*.code-workspace

# ApexBridge Deep Research specific
# Data storage directories
data/lancedb/
data/checkpoints.db
data/*.db
data/*.sqlite

# Vector database files
*. lance
*. lancedb/

# Research outputs
reports/
outputs/
research_results/

# Model caches
model_cache/
.cache/

# Temporary files
tmp/
temp/
*.tmp

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Log files
logs/
*.log

# API keys and secrets (additional protection)
.env.local
.env.development
.env.production
secrets.json
config.json

# Testing artifacts
.coverage
.coverage.*
htmlcov/

# Documentation builds
docs/_build/
site/

# Jupyter Notebook checkpoints
*.ipynb_checkpoints

# pyenv
.python-version

# pipenv
Pipfile.lock

# Celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Stores VSCode versions used for
.vscode-test

# yarn v2 testing VSCode extensions
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

# IntelliJ based IDEs
.idea

# Finder (MacOS)
.Finder_# Docker
.dockerignore
Dockerfile.dev
docker-compose.*

override.yml

# SearXNG config (if custom)
searxng/
*.xml
data/
</file>

<file path="requirements.txt">
# Web & API
fastapi
uvicorn
sse-starlette
httpx

# Search Sources (New)
arxiv
PyGithub
wikipedia

# AI & Orchestration
langgraph
langgraph-checkpoint-sqlite
langchain-text-splitters  # éªŒè¯æ¨¡å—è¿˜åœ¨ç”¨
litellm
tenacity
async_timeout

# Data
pydantic
pydantic_settings
aiosqlite
numpy

# Crawler & Vision
crawl4ai
pymupdf
paddlepaddle
paddleocr>=2.7.0
opencv-python-headless

# Utils
loguru
</file>

<file path="app/api/research.py">
# app/api/research.py
from fastapi import APIRouter
from sse_starlette.sse import EventSourceResponse
from app.modules.orchestrator.graph import build_graph
from app.core.config import settings
# ğŸŸ¢ å¿…é¡»æ¢å› AsyncSqliteSaver
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver 
import aiosqlite
import asyncio
import json
import uuid
import traceback
from async_timeout import timeout 

router = APIRouter()

# è·å–æœªç¼–è¯‘çš„å›¾è°±æ„å»ºå™¨
workflow_builder = build_graph()

@router.get("/stream")
async def stream_research(topic: str):
    # ç”Ÿæˆå”¯ä¸€ä¼šè¯ ID
    thread_id = str(uuid.uuid4())
    task_id = thread_id
    
    config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": settings.MAX_RECURSION_LIMIT
    }

    async def event_generator():
        # åˆå§‹åŒ–çŠ¶æ€
        inputs = {
            "task_id": task_id,
            "task": topic,
            "clarified_intent": topic,
            "plan": [],
            "knowledge_graph": [],
            "reflection_logs": [],
            "iteration_count": 0,
            "max_iterations": 3,
            "topic": topic,          
            "draft_report": "",      
            "final_report": "",     
        }
        
        try:
            async with timeout(settings.GLOBAL_TIMEOUT_SEC):
                
                print(f"ğŸš€ [System] Starting research task: {task_id} (Async + WAL Mode)")
                
                # ğŸŸ¢ 1. ä½¿ç”¨å¼‚æ­¥è¿æ¥
                async with aiosqlite.connect(settings.CHECKPOINT_DB_PATH) as conn:
                    
                    # ğŸ›¡ï¸ã€å…³é”®é˜²æ­»é”é…ç½®ã€‘å¼€å¯ WAL æ¨¡å¼å’Œè¶…æ—¶è®¾ç½®
                    # è¿™å…è®¸è¯»å†™å¹¶å‘ï¼Œå½»åº•è§£å†³ä¹‹å‰çš„å¡æ­»é—®é¢˜
                    await conn.execute("PRAGMA journal_mode=WAL;")
                    await conn.execute("PRAGMA synchronous=NORMAL;")
                    await conn.execute("PRAGMA busy_timeout=30000;") # ç­‰å¾… 30s è€Œä¸æ˜¯ç«‹åˆ»æŠ¥é”™
                    await conn.commit()
                    
                    # ğŸ©¹ å…¼å®¹æ€§è¡¥ä¸ (é˜²æ­¢éƒ¨åˆ†ç‰ˆæœ¬çš„ LangGraph æŠ¥é”™)
                    setattr(conn, "is_alive", lambda: True)
                    
                    # 2. åˆ›å»ºå¼‚æ­¥ Checkpointer
                    checkpointer = AsyncSqliteSaver(conn)
                    
                    # 3. ç¼–è¯‘å›¾è°±
                    graph = workflow_builder.compile(checkpointer=checkpointer)
                    
                    # 4. è¿è¡Œå›¾è°± (astream å¿…é¡»é…å¯¹å¼‚æ­¥ checkpointer)
                    async for event in graph.astream(inputs, config=config):
                        for node_name, state_update in event.items():
                            payload = {
                                "step": node_name,
                                "data": state_update
                            }
                            
                            json_str = json.dumps(
                                payload, 
                                default=str, 
                                ensure_ascii=False
                            )
                            
                            yield {
                                "event": "update",
                                "data": json_str
                            }
                            # ç¼“å†²ä¸€ä¸‹
                            await asyncio.sleep(0.1)

                yield {"event": "finish", "data": "DONE"}

        except asyncio.TimeoutError:
            print(f"â° Task timed out after {settings.GLOBAL_TIMEOUT_SEC}s")
            error_payload = json.dumps(
                {"error": f"Global Timeout: Research stopped after {settings.GLOBAL_TIMEOUT_SEC} seconds."}, 
                ensure_ascii=False
            )
            yield {"event": "error", "data": error_payload}
                
        except Exception as e:
            print(f"âŒ Error in stream: {e}")
            traceback.print_exc()
            error_payload = json.dumps({"error": str(e)}, ensure_ascii=False)
            yield {"event": "error", "data": error_payload}

    return EventSourceResponse(event_generator())
</file>

<file path="app/core/config.py">
# app/core/config.py
from pydantic_settings import BaseSettings
from pydantic import field_validator
from typing import List, Union, Any
import os

class Settings(BaseSettings):
    # --- åŸºç¡€é…ç½® ---
    API_HOST: str = "0.0.0.0"
    API_PORT: int = 23800
    
    # ğŸŸ¢ æ–°å¢ï¼šä»»åŠ¡æ–‡ä»¶å­˜å‚¨æ ¹ç›®å½•
    TASK_STORAGE_DIR: str = "./data/tasks"
    
    # çŠ¶æ€æ£€æŸ¥ç‚¹ (ä¿æŒ SQLite ä»¥ç®¡ç†çŠ¶æ€æœº)
    CHECKPOINT_DB_PATH: str = "./data/checkpoints.db"
    
    # æŠ¥å‘Šè¾“å‡º
    SAVE_REPORT_TO_FILE: bool = True
    REPORT_OUTPUT_DIR: str = "./outputs"

    # --- æœç´¢é…ç½® ---
    SEARCH_PROVIDER: str = "tavily"
    TAVILY_API_KEYS: Union[str, List[str]] = []

    @field_validator("TAVILY_API_KEYS", mode="before")
    @classmethod
    def parse_api_keys(cls, v: Any) -> List[str]:
        if isinstance(v, str) and not v.strip().startswith("["):
            return [k.strip() for k in v.split(",") if k.strip()]
        return v or []

    # æ·±åº¦ç ”ç©¶å»ºè®®è®¾ä¸º 5-10ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ OCR äº†ï¼Œèƒ½å¤„ç†æ›´å¤šèµ„æ–™
    MAX_SEARCH_RESULTS: int = 6 

    # --- æ¨¡å‹é…ç½® ---
    DEEPSEEK_API_KEY: str | None = None
    GLOBAL_TIMEOUT_SEC: int = 1200

    # ğŸŸ¢ ç®€åŒ–ä¸ºä¸¤ç±»æ¨¡å‹é…ç½®
    # ç”¨äºæ¨ç†ä»»åŠ¡ (Planner, Critic, MAD Debate)
    MODEL_REASONING: str = "deepseek/deepseek-reasoner"
    # ç”¨äºç”Ÿæˆä»»åŠ¡ (Writer, Fast, Long context)
    MODEL_CHAT: str = "deepseek/deepseek-chat"

    # --- é«˜çº§é…ç½® ---
    MAX_RECURSION_LIMIT: int = 25

    # ğŸŸ¢ å‚ç›´æœç´¢é…ç½®
    GITHUB_TOKEN: str | None = None # å¼ºçƒˆå»ºè®®é…ç½®ï¼Œå¦åˆ™æ¯å°æ—¶åªèƒ½è°ƒ 60 æ¬¡
    
    ENABLE_ARXIV: bool = True
    ENABLE_GITHUB: bool = True
    ENABLE_WIKI: bool = True
    
    # æ··åˆæœç´¢æƒé‡
    Result_Count_Arxiv: int = 3
    Result_Count_Github: int = 3
    Result_Count_Wiki: int = 2
    Result_Count_Web: int = 3

    class Config:
        env_file = ".env"
        extra = "ignore"

settings = Settings()

os.makedirs(os.path.dirname(settings.CHECKPOINT_DB_PATH), exist_ok=True)
os.makedirs(settings.TASK_STORAGE_DIR, exist_ok=True)
if settings.SAVE_REPORT_TO_FILE:
    os.makedirs(settings.REPORT_OUTPUT_DIR, exist_ok=True)
</file>

<file path="app/modules/insight/prompts.py">
# app/modules/insight/prompts.py
from textwrap import dedent

class ResearchPrompts:
    """
    ç»Ÿä¸€ç®¡ç†ç³»ç»Ÿä¸­çš„æ‰€æœ‰ Prompt æ¨¡æ¿ã€‚
    ä½¿ç”¨ dedent å»é™¤ç¼©è¿›ï¼Œä¿æŒ Prompt å¹²å‡€ã€‚
    """

    # ==================== Clarifier (æ¾„æ¸…è€…) ====================

    @staticmethod
    def clarification_check(topic: str) -> str:
        """[æ¾„æ¸…è€…] æ£€æŸ¥ç ”ç©¶ä¸»é¢˜æ˜¯å¦å­˜åœ¨æ­§ä¹‰"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç ”ç©¶å‘˜ã€‚ç”¨æˆ·æå‡ºäº†ç ”ç©¶ä¸»é¢˜ï¼š"{topic}"ã€‚
            è¯·åˆ¤æ–­è¯¥ä¸»é¢˜æ˜¯å¦å­˜åœ¨é‡å¤§æ­§ä¹‰ï¼ˆä¾‹å¦‚æ—¶é—´èŒƒå›´ä¸æ˜ã€å¯¹è±¡ä¸æ˜ç¡®ã€èƒŒæ™¯ç¼ºå¤±ï¼‰ã€‚

            å¦‚æœå­˜åœ¨æ­§ä¹‰ï¼Œè¯·ç”Ÿæˆ 1-3 ä¸ªæ¾„æ¸…é—®é¢˜ï¼Œå¹¶ç»™å‡ºä½ è®¤ä¸ºæœ€åˆç†çš„ã€é»˜è®¤å‡è®¾ã€‘ã€‚
            å¦‚æœéå¸¸æ¸…æ™°ï¼Œè¯·ç›´æ¥è¿”å› "CLEAR"ã€‚

            è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰:
            {{
                "is_clear": boolean,
                "reason": "è§£é‡Šä¸ºä»€ä¹ˆä¸æ¸…",
                "questions": ["é—®é¢˜1", "é—®é¢˜2"],
                "assumptions": "å¦‚æœç”¨æˆ·ä¸å›ç­”ï¼Œæˆ‘å°†é»˜è®¤ç ”ç©¶..."
            }}
        """).strip()

    # ==================== Planner (è§„åˆ’è€…) ====================

    @staticmethod
    def outline_generation(topic: str, intent: str) -> str:
        """[è§„åˆ’è€…] ç”Ÿæˆç ”ç©¶æŠ¥å‘Šå¤§çº²ç»“æ„"""
        return dedent(f"""
            ç ”ç©¶ä¸»é¢˜ï¼š{topic}
            è¯¦ç»†æ„å›¾ï¼š{intent}

            è¯·ç”Ÿæˆä¸€ä»½æ·±åº¦ç ”ç©¶æŠ¥å‘Šçš„ã€å¤§çº²ç»“æ„ã€‘ã€‚è¿™å°†ä½œä¸ºåç»­ç ”ç©¶çš„éª¨æ¶ã€‚

            è¦æ±‚ï¼š
            1. åŒ…å« 4-6 ä¸ªæ ¸å¿ƒç« èŠ‚ï¼ˆä¸å«æ‘˜è¦å’Œç»“è®ºï¼‰ã€‚
            2. æ¯ä¸ªç« èŠ‚å¿…é¡»æ˜¯ä¸€ä¸ªå…·ä½“çš„è°ƒç ”æ–¹å‘ï¼Œé€»è¾‘é€’è¿›ã€‚
            3. é¿å…ç©ºæ³›çš„æ ‡é¢˜ï¼Œè¦å…·ä½“ã€‚

            è¾“å‡ºæ ¼å¼ï¼ˆJSON Listï¼‰:
            ["1. å…¨çƒå¸‚åœºè§„æ¨¡ä¸å¢é•¿é©±åŠ¨åŠ›åˆ†æ", "2. NexaAI çš„æ ¸å¿ƒæŠ€æœ¯æ¶æ„æ‹†è§£", "3. ..."]
        """).strip()

    @staticmethod
    def planner_tasks_from_outline(topic: str, outline: list, existing_plan_json: str) -> str:
        """[è§„åˆ’è€…] åŸºäºå¤§çº²æ‹†è§£æœç´¢ä»»åŠ¡"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®ç»ç†ã€‚åŸºäºä»¥ä¸‹ç ”ç©¶å¤§çº²ï¼Œæ‹†è§£å…·ä½“çš„æœç´¢ä»»åŠ¡ã€‚

            ã€ç ”ç©¶ä¸»é¢˜ã€‘ï¼š{topic}
            ã€ç ”ç©¶å¤§çº²ã€‘ï¼š
            {outline}

            ã€å½“å‰å·²æœ‰çš„è®¡åˆ’ã€‘ï¼š
            {existing_plan_json}

            ã€ä»»åŠ¡ã€‘ï¼š
            è¯·ä¸ºå¤§çº²ä¸­ã€å°šæœªå……åˆ†ç ”ç©¶ã€‘çš„ç« èŠ‚ç”Ÿæˆæœç´¢ä»»åŠ¡ã€‚

            ã€è¦æ±‚ã€‘ï¼š
            1. æ¯ä¸ªä»»åŠ¡å¿…é¡»æ˜ç¡®æœåŠ¡äºæŸä¸ªå¤§çº²ç« èŠ‚ã€‚
            2. ä»»åŠ¡å¿…é¡»å…·ä½“ï¼ˆä¾‹å¦‚ "æœç´¢ X çš„ç™½çš®ä¹¦" è€Œä¸æ˜¯ "æœç´¢ X"ï¼‰ã€‚
            3. å»ºç«‹åˆç†çš„ä¾èµ–å…³ç³»ã€‚

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            ä¸¥æ ¼è¿”å› JSON åˆ—è¡¨ï¼š
            [
                {{
                    "id": "task_market_1",
                    "description": "é’ˆå¯¹ç« èŠ‚1ï¼Œæœç´¢2024å¹´ç›¸å…³å¸‚åœºæŠ¥å‘Šæ•°æ®",
                    "dependencies": [],
                    "related_section": "1. å…¨çƒå¸‚åœºè§„æ¨¡..."
                }}
            ]
        """).strip()

    @staticmethod
    def planner_dag_replanning(topic: str, existing_plan_json: str, feedback: str) -> str:
        """[è§„åˆ’è€…] æ ¹æ® Critic åé¦ˆè¿½åŠ æ–°ä»»åŠ¡"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªæ•æ·çš„é¡¹ç›®ç»ç†ã€‚æˆ‘ä»¬å¯¹ '{topic}' çš„åˆæ­¥ç ”ç©¶æ”¶åˆ°äº†æ‰¹è¯„åé¦ˆï¼Œéœ€è¦è¡¥å……è°ƒæŸ¥ã€‚

            ã€å½“å‰å·²å®Œæˆçš„è®¡åˆ’ã€‘ï¼š
            {existing_plan_json}

            ã€æ‰¹è¯„ä¸å»ºè®®ã€‘ï¼š
            {feedback}

            ã€ä»»åŠ¡ã€‘ï¼š
            è¯·æ ¹æ®å»ºè®®ï¼Œç”Ÿæˆ **1-3 ä¸ªæ–°çš„è¡¥æ•‘ä»»åŠ¡**ï¼Œæ·»åŠ åˆ°ç°æœ‰çš„ DAG ä¸­ã€‚

            ã€è¦æ±‚ã€‘ï¼š
            1. æ–°ä»»åŠ¡çš„ ID å¿…é¡»ä¸ä¸ç°æœ‰ ID å†²çªï¼ˆå»ºè®®ä½¿ç”¨ "fix_task_1", "fix_task_2" ç­‰ï¼‰ã€‚
            2. æ–°ä»»åŠ¡å¯ä»¥ä¾èµ–ç°æœ‰çš„å·²å®Œæˆä»»åŠ¡ã€‚
            3. åªè¿”å›æ–°å¢ä»»åŠ¡çš„ JSON åˆ—è¡¨ã€‚

            ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ã€‘ï¼š
            [
                {{
                    "id": "fix_data_2024",
                    "description": "æœç´¢æœ€æ–°çš„2024å¹´Q4è¥æ”¶æ•°æ®ä»¥ä¿®æ­£è¿‡æ—¶ä¿¡æ¯",
                    "dependencies": ["task_1"]
                }}
            ]
        """).strip()

    # ==================== Searcher (æœç´¢è€…) ====================

    @staticmethod
    def search_result_selection(task_description: str, snippets_text: str, num_select: int = 3) -> str:
        """[æœç´¢è€…] ä»æœç´¢ç»“æœä¸­ç­›é€‰é«˜ä»·å€¼é“¾æ¥"""
        return dedent(f"""
            ä»»åŠ¡ç›®æ ‡ï¼š{task_description}

            ä»¥ä¸‹æ˜¯æœç´¢å¼•æ“è¿”å›çš„ç»“æœç‰‡æ®µï¼š
            {snippets_text}

            ã€ä»»åŠ¡ã€‘ï¼š
            è¯·ä»ä¸­ç­›é€‰å‡º {num_select} ä¸ªæœ€æœ‰ä»·å€¼ã€ä¿¡æ¯é‡æœ€å¤§ã€æœ€å¯èƒ½åŒ…å«å¹²è´§ï¼ˆå¦‚PDFã€å®˜æ–¹æ–‡æ¡£ã€æŠ€æœ¯åšå®¢ï¼‰çš„é“¾æ¥ã€‚

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            ä¸¥æ ¼è¿”å› JSON åˆ—è¡¨ï¼ŒåªåŒ…å«é€‰ä¸­çš„ urlï¼š
            ["https://example.com/report.pdf", "https://github.com/xx/xx"]
        """).strip()

    # ==================== Analyst (åˆ†æå¸ˆ) ====================

    @staticmethod
    def analyst_incremental_reading(topic: str, existing_notes: str, new_document: str) -> str:
        """[åˆ†æå¸ˆ] å¢é‡é˜…è¯»æ–‡æ¡£å¹¶æ•´åˆç¬”è®°"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œæ·±åº¦è°ƒç ”çš„ç ”ç©¶å‘˜ã€‚
            ç ”ç©¶ä¸»é¢˜ï¼š"{topic}"

            è¿™æ˜¯ä½ ã€ç›®å‰çš„è°ƒç ”ç¬”è®°ã€‘ï¼š
            (å¦‚æœæ²¡æœ‰ç¬”è®°ï¼Œæ˜¾ç¤ºä¸º "æš‚æ— ")
            =========================================
            {existing_notes}
            =========================================

            è¿™æ˜¯ä½ åˆšæ‹¿åˆ°çš„ã€ä¸€ä»½æ–°èµ„æ–™ã€‘(Markdownæ ¼å¼ï¼ŒåŒ…å«å…ƒæ•°æ®)ï¼š
            =========================================
            {new_document}
            =========================================

            ã€ä»»åŠ¡ã€‘ï¼š
            è¯·é˜…è¯»è¿™ä»½æ–°èµ„æ–™ï¼Œå°†å…¶ä¸­çš„**å…³é”®ä¿¡æ¯ã€æ•°æ®ã€æŠ€æœ¯ç»†èŠ‚**æ•´åˆè¿›ä½ çš„ã€è°ƒç ”ç¬”è®°ã€‘ä¸­ã€‚

            ã€ä¸¥æ ¼è¦æ±‚ã€‘ï¼š
            1. **å¢é‡æ›´æ–°**ï¼šä¿ç•™ç¬”è®°ä¸­å·²æœ‰çš„æœ‰ä»·å€¼ä¿¡æ¯ï¼Œä¸è¦åˆ é™¤ï¼Œé™¤éæ–°èµ„æ–™è¯æ˜æ—§ä¿¡æ¯æ˜¯é”™çš„ã€‚
            2. **å¼•ç”¨æº¯æº (CRITICAL)**ï¼šä»æ–°èµ„æ–™ä¸­æå–ä¿¡æ¯æ—¶ï¼Œ**å¿…é¡»**åœ¨å¥å°¾åŠ ä¸Šæ¥æºæ ‡è®°ã€‚
               - æ ¼å¼ï¼š`[Source: <url_from_new_document_header>]`
               - æ–°èµ„æ–™çš„ URL åœ¨æ–‡ä»¶å¼€å¤´çš„ `url: ...` å­—æ®µä¸­ã€‚
            3. **ç»“æ„åŒ–**ï¼šç¬”è®°åº”ä¿æŒæ¸…æ™°çš„å±‚çº§ç»“æ„ï¼ˆå¦‚ï¼šæŠ€æœ¯æ¶æ„ã€å¸‚åœºæ•°æ®ã€ç«å“åˆ†æï¼‰ã€‚
            4. **å»é‡**ï¼šå¦‚æœæ–°èµ„æ–™è®²çš„å†…å®¹ç¬”è®°é‡Œå·²ç»æœ‰äº†ï¼Œä¸”æ²¡æœ‰æ›´å¤šç»†èŠ‚ï¼Œåˆ™å¿½ç•¥ï¼Œä¸è¦é‡å¤ã€‚

            è¯·è¾“å‡ºã€æ›´æ–°åçš„è°ƒç ”ç¬”è®°ã€‘ï¼š
        """).strip()

    @staticmethod
    def analyst_reasoning(topic: str, context: str) -> str:
        """[åˆ†æå¸ˆ] RAG åˆ†æä¸ Gap è¯†åˆ« (é€‚ç”¨äº DeepSeek R1)"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ·±åº¦ç ”ç©¶å‘˜ã€‚åŸºäºä»¥ä¸‹ã€å·²æ ¸å®çš„çŸ¥è¯†åº“ç‰‡æ®µã€‘è¿›è¡Œåˆ†æã€‚

            ã€å·²æ ¸å®ä¿¡æ¯ã€‘ï¼š
            {context}

            ã€ä»»åŠ¡ã€‘ï¼š
            1. ç»¼åˆç›®å‰å…³äº '{topic}' çš„æ‰€æœ‰ä¿¡æ¯ï¼Œå†™ä¸€æ®µæ·±åº¦åˆ†æï¼ˆDraftï¼‰ã€‚
            2. æ‰¹åˆ¤æ€§åœ°æŒ‡å‡ºï¼šæˆ‘ä»¬è¿˜**ç¼ºå°‘**ä»€ä¹ˆå…³é”®æ•°æ®æˆ–è§†è§’ï¼Ÿ(Gap Analysis)ã€‚

            ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
            - å¦‚æœä¿¡æ¯å·²ç»éå¸¸å……åˆ†ï¼Œèƒ½å¤Ÿå›ç­” '{topic}' çš„æ ¸å¿ƒé—®é¢˜ï¼ŒGap è¯·å›å¤ "æ— "ã€‚
            - å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·åœ¨ Gap éƒ¨åˆ†æ˜ç¡®æŒ‡å‡ºä¸‹ä¸€æ­¥éœ€è¦æœä»€ä¹ˆï¼ˆä¾‹å¦‚ï¼š"ç¼ºä¹å…·ä½“çš„2024å¹´Q4æˆæœ¬æ•°æ®"ï¼‰ã€‚
            - ä¿æŒå®¢è§‚ã€ä¸­ç«‹ï¼Œç”¨æ•°æ®è¯´è¯ã€‚
        """).strip()

    # ==================== Critic (æ‰¹è¯„å®¶) ====================

    @staticmethod
    def critic_evaluation(topic: str, draft: str) -> str:
        """[æ‰¹è¯„å®¶] è¯„ä¼°è‰ç¨¿è´¨é‡ä¸å¹»è§‰"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å­¦æœ¯å®¡ç¨¿äººã€‚è¯·è¯„ä¼°å…³äº '{topic}' çš„ç ”ç©¶è‰ç¨¿ã€‚

            ã€å¾…è¯„è‰ç¨¿ã€‘ï¼š
            {draft}

            ã€è¯„ä¼°æ ‡å‡†ã€‘ï¼š
            1. **æ•°æ®æ”¯æ’‘ (30åˆ†)**: æ˜¯å¦æœ‰å…·ä½“çš„æ•°å­—ã€æ—¥æœŸã€å®ä½“ï¼Ÿ(ç©ºæ³›çš„æè¿°æ‰£åˆ†)
            2. **é€»è¾‘é—­ç¯ (30åˆ†)**: ç»“è®ºæ˜¯å¦ç”±è®ºæ®æ¨å¯¼å¾—å‡ºï¼Ÿ
            3. **å›ç­”åˆ‡é¢˜ (20åˆ†)**: æ˜¯å¦è§£å†³äº†ç”¨æˆ·æœ€åˆçš„ç ”ç©¶æ„å›¾ï¼Ÿ
            4. **ä¿¡æ¯æ·±åº¦ (20åˆ†)**: æ˜¯å¦æä¾›äº†è¶…è¶Šå¸¸è¯†çš„æ´å¯Ÿï¼Ÿ

            ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
            è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦è¾“å‡º Markdown ä»£ç å—ï¼Œç›´æ¥è¾“å‡º JSONï¼‰ï¼š
            {{
                "score": <0-10åˆ†ï¼Œæ€»åˆ†/10>,
                "critique": "<å…·ä½“çš„æ‰¹è¯„æ„è§ï¼ŒæŒ‡å‡ºå“ªé‡Œç¼ºæ•°æ®ï¼Œå“ªé‡Œé€»è¾‘ä¸é€š>",
                "adjustment": "<ç»™è§„åˆ’è€…çš„å…·ä½“å»ºè®®ï¼Œä¾‹å¦‚ï¼š'æœç´¢Xå…¬å¸çš„è´¢æŠ¥'ï¼Œ'æŸ¥æ‰¾YæŠ€æœ¯çš„åŸç†å›¾'>"
            }}
        """).strip()

    # ==================== Publisher (å‡ºç‰ˆè€…) ====================

    @staticmethod
    def publisher_final_report(topic: str, draft_context: str) -> str:
        """[å‡ºç‰ˆè€…] ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š (å¢å¼ºç‰ˆ)"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‡ºç‰ˆç¼–è¾‘å’Œç§‘æŠ€æŠ¥å‘Šä½œå®¶ã€‚
            ä¸»é¢˜ï¼š'{topic}'
            ã€è¾“å…¥ææ–™ã€‘ï¼š
            è¿™æ˜¯ä¸€ä»½ç”±èµ„æ·±åˆ†æå¸ˆæ’°å†™å¹¶ç»è¿‡äº‹å®æ ¸æŸ¥çš„**æ·±åº¦ç ”ç©¶è‰ç¨¿**ï¼š
            =========================================
            {draft_context}
            =========================================

            ã€ä»»åŠ¡ã€‘ï¼š
            è¯·å°†è¿™ä»½è‰ç¨¿æ•´ç†ä¸ºä¸€ä»½å®Œç¾çš„**æœ€ç»ˆç ”ç©¶æŠ¥å‘Š**ã€‚

            ã€è¦æ±‚ã€‘ï¼š

            1. **æ‰§è¡Œæ‘˜è¦ (Executive Summary)**ï¼š
               - æ”¾åœ¨æŠ¥å‘Šæœ€å¼€å¤´
               - 150-300 å­—
               - åŒ…å«ï¼šç ”ç©¶èƒŒæ™¯ã€æ ¸å¿ƒå‘ç°ã€å…³é”®ç»“è®º
               - è¯»è€…åº”èƒ½é€šè¿‡æ‘˜è¦äº†è§£æŠ¥å‘Šç²¾é«“

            2. **ç»“æ„ä¼˜åŒ–**ï¼š
               - ç¡®ä¿æœ‰æ¸…æ™°çš„ æ‘˜è¦ã€ç›®å½•ã€æ­£æ–‡ç« èŠ‚ã€ç»“è®ºã€å‚è€ƒèµ„æ–™
               - ç« èŠ‚æ ‡é¢˜ä½¿ç”¨ "##" äºŒçº§æ ‡é¢˜
               - ä¿æŒé€»è¾‘é€’è¿›

            3. **æ•°æ®å¯è§†åŒ–**ï¼š
               - å¯¹äºå…³é”®æ•°æ®ï¼ˆå¢é•¿ç‡ã€å¸‚åœºä»½é¢ã€è¥æ”¶ç­‰ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨è¡¨æ ¼å‘ˆç°
               - è¡¨æ ¼æ ¼å¼ç¤ºä¾‹ï¼š
                 | æŒ‡æ ‡ | 2023å¹´ | 2024å¹´ | åŒæ¯”å˜åŒ– |
                 |------|--------|--------|----------|
                 | xxx  | xxx    | xxx    | +xx%     |
               - ä¸è¦ä½¿ç”¨ ASCII art å›¾è¡¨

            4. **å¼•ç”¨ä¿ç•™**ï¼š
               - ç»å¯¹ä¸è¦åˆ é™¤è‰ç¨¿ä¸­çš„ `[Source: ...]` å¼•ç”¨æ ‡è®°
               - åœ¨æ­£æ–‡ä¸­å¼•ç”¨å…·ä½“æ•°æ®æ—¶ï¼Œå¿…é¡»åœ¨å¥æœ«æ ‡æ³¨æ¥æº

            5. **å‚è€ƒèµ„æ–™åˆ—è¡¨**ï¼š
               - åœ¨æŠ¥å‘Šæœ«å°¾ç”Ÿæˆå‚è€ƒèµ„æ–™åˆ—è¡¨
               - æ ¼å¼ï¼š- [æ ‡é¢˜](URL)

            6. **è¯­è¨€é£æ ¼**ï¼š
               - å®¢è§‚ã€ä¸“ä¸šã€è¯¦å®
               - é¿å…å£è¯­åŒ–è¡¨è¾¾
               - åªåšè¯­æ–‡æ¶¦è‰²å’Œæ ¼å¼è°ƒæ•´ï¼Œä¸åˆ å‡ä¿¡æ¯

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„å®Œæ•´æŠ¥å‘Šï¼Œä¸è¦æœ‰å‰è¨€æˆ–è§£é‡Šã€‚
        """).strip()

    # ==================== Verification (éªŒè¯è€…) ====================

    @staticmethod
    def verification_claims_extraction(text: str) -> str:
        """[éªŒè¯è€…] æå–äº‹å®æ–­è¨€"""
        return dedent(f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº‹å®æ ¸æŸ¥å‘˜ã€‚è¯·ä»ä¸‹é¢çš„æ–‡æœ¬ä¸­æå– 3-5 ä¸ªæœ€å…³é”®çš„ã€åŒ…å«å…·ä½“æ•°æ®æˆ–ç¡®å®šæ€§é™ˆè¿°çš„äº‹å®æ–­è¨€ã€‚

            ã€å¾…æå–æ–‡æœ¬ã€‘ï¼š
            {text}

            ã€æå–è¦æ±‚ã€‘ï¼š
            1. **åªæå–å®¢è§‚äº‹å®**ï¼šå¦‚é‡‘é¢ã€å¢é•¿ç‡ã€å…·ä½“æ—¥æœŸã€å®ä½“å…³ç³»ã€å¹¶è´­äº‹ä»¶ã€‚
            2. **å®ç¼ºæ¯‹æ»¥**ï¼šåªæå–åŒ…å«**å…·ä½“æ•°å­—ã€æ—¥æœŸã€ç‰¹å®šå®ä½“è¡Œä¸ºã€æ˜ç¡®å› æœå…³ç³»**çš„å¥å­ã€‚
            3. **å¿½ç•¥ç©ºæ³›å†…å®¹**ï¼šå¦‚æœè¯¥ç‰‡æ®µåªæ˜¯ä»‹ç»èƒŒæ™¯ã€è¿‡æ¸¡è¯­å¥æˆ–ä¸»è§‚è¯„è®ºï¼Œä¸åŒ…å«ç¡¬æ ¸äº‹å®ï¼Œè¯·è¿”å›ç©ºåˆ—è¡¨ã€‚
            4. **å¿½ç•¥ä¸»è§‚è§‚ç‚¹**ï¼šå¿½ç•¥"æˆ‘è®¤ä¸º"ã€"å¯èƒ½"ã€"é¢„è®¡"ç­‰æ¨¡ç³Šæè¿°ã€‚
            5. **åŸå­åŒ–**ï¼šæ¯ä¸ªæ–­è¨€åº”è¯¥æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å¥å­ã€‚

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            è¯·ä¸¥æ ¼ä»…è¿”å› JSON åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
            [
                {{
                    "original_text": "åŸæ–‡ç‰‡æ®µ...",
                    "claim": "é‡å†™åçš„ç‹¬ç«‹äº‹å®é™ˆè¿°"
                }}
            ]
        """).strip()

    @staticmethod
    def verification_claim_check(claim: str, context: str) -> str:
        """[éªŒè¯è€…] åŸºäºæœç´¢ç»“æœæ ¸æŸ¥æ–­è¨€"""
        return dedent(f"""
            è¯·æ ¹æ®æä¾›çš„æœç´¢è¯æ®ï¼ŒéªŒè¯ä»¥ä¸‹æ–­è¨€çš„çœŸå®æ€§ã€‚

            ã€å¾…éªŒè¯æ–­è¨€ã€‘ï¼š
            {claim}

            ã€æœç´¢åˆ°çš„è¯æ®ã€‘ï¼š
            {context}

            ã€åˆ¤å®šé€»è¾‘ã€‘ï¼š
            - **Verified (å·²éªŒè¯)**: è¯æ®ä¸­æœ‰æ˜ç¡®æ•°æ®æ”¯æŒè¯¥æ–­è¨€ã€‚
            - **Disputed (æœ‰äº‰è®®)**: è¯æ®ä¸­çš„æ•°æ®/äº‹å®ä¸æ–­è¨€ç›´æ¥å†²çªï¼ˆä¾‹å¦‚ï¼šæ–­è¨€è¯´å¢é•¿50%ï¼Œè¯æ®è¯´ä¸‹é™10%ï¼‰ã€‚
            - **Unconfirmed (æœªç¡®è®¤)**: è¯æ®ä¸è¶³ï¼Œæˆ–è¯æ®ä¸æ–­è¨€æ— å…³ã€‚

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            è¯·ä¸¥æ ¼ä»…è¿”å› JSON å¯¹è±¡ï¼š
            {{
                "status": "Verified" | "Disputed" | "Unconfirmed",
                "explanation": "ä¸€å¥è¯è§£é‡Šç†ç”±ï¼Œå¼•ç”¨è¯æ®ä¸­çš„æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰"
            }}
        """).strip()

    # ==================== MAD Debate (è¾©è®ºæ¡†æ¶) ====================

    @staticmethod
    def debate_argument(topic: str, stance: str, context: str) -> str:
        """[è¾©æ‰‹] ç”Ÿæˆè¾©è®ºé™ˆè¿°"""
        return dedent(f"""
            ä½ æ­£åœ¨å‚ä¸ä¸€åœºå…³äº '{topic}' çš„ä¸¥è‚ƒè¾©è®ºã€‚

            ã€ä½ çš„ç«‹åœºã€‘ï¼š{stance} (è¯·æåŠ›å¯»æ‰¾è¯æ®æ”¯æŒæ­¤ç«‹åœºï¼Œæˆ–åé©³å¯¹æ–¹)

            ã€å¯ç”¨è¯æ®ã€‘ï¼š
            {context}

            ã€è¦æ±‚ã€‘ï¼š
            1. é€»è¾‘ä¸¥å¯†ï¼Œé’ˆé”‹ç›¸å¯¹ã€‚
            2. å¿…é¡»æ˜¾å¼å¼•ç”¨è¯æ®ï¼ˆå¦‚ "æ ¹æ®[Source 1]..."ï¼‰ã€‚
            3. ä¿æŒç®€çŸ­æœ‰åŠ›ï¼ˆ200å­—ä»¥å†…ï¼‰ã€‚

            è¯·è¾“å‡ºä½ çš„è¾©è®ºé™ˆè¿°ï¼š
        """).strip()

    @staticmethod
    def debate_judgment(topic: str, affirmative_arg: str, negative_arg: str) -> str:
        """[æ³•å®˜] æœ€ç»ˆè£å†³"""
        return dedent(f"""
            ä½œä¸ºä¸­ç«‹çš„å¤§æ³•å®˜ï¼Œè¯·æ ¹æ®åŒæ–¹è¾©è¯å¯¹ '{topic}' åšå‡ºçœŸç†è£å†³ã€‚

            ã€æ­£æ–¹è§‚ç‚¹ã€‘ï¼š
            {affirmative_arg}

            ã€åæ–¹è§‚ç‚¹ã€‘ï¼š
            {negative_arg}

            ã€åˆ¤å†³æ ‡å‡†ã€‘ï¼š
            1. è°çš„è¯æ®æ›´æƒå¨ã€æ›´æ–°ï¼Ÿ
            2. è°çš„é€»è¾‘é“¾æ¡æ›´å®Œæ•´ï¼Ÿ
            3. å¿½ç•¥ä¿®è¾æŠ€å·§ï¼Œåªçœ‹äº‹å®å¯†åº¦ã€‚

            ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
            è¯·è¿”å› JSONï¼š
            {{
                "winner": "Affirmative" | "Negative" | "Uncertain",
                "conclusion": "æœ€ç»ˆè®¤å®šçš„äº‹å®ç»“è®º",
                "reasoning": "åˆ¤å†³ç†ç”±"
            }}
        """).strip()


# å®ä¾‹åŒ–ï¼ˆå¦‚æœéœ€è¦å•ä¾‹ï¼Œæˆ–è€…ç›´æ¥ç”¨é™æ€æ–¹æ³•ï¼‰
prompts = ResearchPrompts()
</file>

<file path="app/modules/orchestrator/graph.py">
# app/modules/orchestrator/graph.py

from langgraph.graph import StateGraph, END
import json,os

from app.core.config import settings
from app.core.utils import parse_json_safe
from app.modules.orchestrator.state import ResearchState
from app.modules.orchestrator.dag import DAGManager, TaskStatus
from app.modules.perception.search import search_generic as search_tool
from app.modules.perception.crawler import crawl_urls
from app.core.llm import simple_llm_call
# å¼•å…¥æ–°çš„æ–‡ä»¶å­˜å‚¨
from app.modules.knowledge.file_store import FileKnowledgeStore
from app.modules.insight.prompts import prompts
from app.modules.verification.verification_agent import VerificationAgent
from app.modules.utils.file_utils import save_markdown_report

# åˆå§‹åŒ–æ–‡ä»¶å­˜å‚¨
kb = FileKnowledgeStore()

# --- è¾…åŠ©å‡½æ•° ---

def log_step(step_name: str, content: dict):
    print(f"\nğŸš€ [Step: {step_name}]")
    try:
        text = json.dumps(content, indent=2, ensure_ascii=False, default=str)
        if len(text) > 2000:
            print(text[:2000] + "\n... (truncated)")
        else:
            print(text)
    except:
        print(str(content)[:2000])
    print("-" * 50)

# --- èŠ‚ç‚¹é€»è¾‘ ---

async def node_clarifier(state: ResearchState):
    print("--- [Clarifier] Checking Ambiguity ---")
    if state.get("clarified_intent"): return {}
    prompt = prompts.clarification_check(state["task"])
    response = await simple_llm_call(prompt, model=settings.MODEL_REASONING)
    result = parse_json_safe(response)
    
    if result and not result.get("is_clear", True):
        assumptions = result.get("assumptions", "Default assumptions")
        questions = result.get("questions", [])
        print(f"âš ï¸ Ambiguity Detected: {questions}")
        print(f"ğŸ¤– Auto-resolving: {assumptions}")
        new_intent = f"{state['task']} (Context: {assumptions})"
        return {"needs_clarification": True, "clarified_intent": new_intent, "clarification_history": questions}
    return {"needs_clarification": False, "clarified_intent": state["task"]}

async def node_planner(state: ResearchState):
    print(f"--- [Planner] (Model: {settings.MODEL_REASONING}) ---")
    dag = DAGManager(state["plan"])
    model_to_use = settings.MODEL_REASONING
    intent = state.get("clarified_intent", state["task"])
    
    # 1. å¤§çº²ç”Ÿæˆ
    current_outline = state.get("outline", [])
    if not current_outline:
        print("ğŸ“ [Planner] Generating Research Outline...")
        outline_resp = await simple_llm_call(prompts.outline_generation(state["task"], intent), model=model_to_use)
        current_outline = parse_json_safe(outline_resp) or []
        print(f"ğŸ“‘ Outline: {current_outline}")
    
    # 2. ä»»åŠ¡ç”Ÿæˆ
    has_feedback = False
    if state["reflection_logs"]:
        last_log = state["reflection_logs"][-1]
        if last_log.get("score", 0) < 8.0:
            print(f"ğŸ”„ [Planner] Replanning based on critique...")
            has_feedback = True
            feedback_str = f"æ‰¹è¯„: {last_log.get('critique')}\nå»ºè®®: {last_log.get('adjustment')}"
            plan_str = json.dumps(dag.to_state(), ensure_ascii=False)
            resp = await simple_llm_call(prompts.planner_dag_replanning(intent, plan_str, feedback_str), model=model_to_use)
            new_tasks = parse_json_safe(resp) or []
            # é˜²å¾¡æ€§å¤„ç†
            if isinstance(new_tasks, list):
                for t in new_tasks:
                    if isinstance(t, dict) and "id" in t and "description" in t:
                        dag.add_task(t["id"], t["description"], t.get("dependencies", []))
    
    if not dag.tasks and not has_feedback:
        print("ğŸ“ [Planner] Generating Tasks from Outline...")
        plan_str = json.dumps(dag.to_state(), ensure_ascii=False)
        resp = await simple_llm_call(prompts.planner_tasks_from_outline(intent, current_outline, plan_str), model=model_to_use)
        new_tasks = parse_json_safe(resp) or []

        # é˜²å¾¡æ€§å¤„ç†ï¼šç¡®ä¿ new_tasks æ˜¯å­—å…¸åˆ—è¡¨
        if isinstance(new_tasks, list):
            valid_tasks = []
            for t in new_tasks:
                if isinstance(t, dict) and "id" in t and "description" in t:
                    valid_tasks.append(t)
                else:
                    print(f"âš ï¸ [Planner] Skipping invalid task format: {t}")
            for t in valid_tasks:
                dag.add_task(t["id"], t["description"], dependencies=t.get("dependencies", []), related_section=t.get("related_section"))
            
    ready_tasks = dag.get_ready_tasks()
    current_queries = [t.description for t in ready_tasks]
    for t in ready_tasks: dag.set_task_running(t.id)
    
    log_step("Planner", {"outline": current_outline, "plan": dag.to_state()})
    return {"outline": current_outline, "plan": dag.to_state(), "search_queries": current_queries}

async def node_search_execute(state: ResearchState):
    print("ğŸ”„ [Search Node] Entered...", flush=True)
    dag = DAGManager(state["plan"])
    running_tasks = [t for t in dag.tasks.values() if t.status == TaskStatus.RUNNING]
    
    if not running_tasks:
        print("âš ï¸ [Search Node] No running tasks found!")
        return {}

    print(f"--- [Search] Processing {len(running_tasks)} tasks ---", flush=True)
    collected_docs = []
    
    for task in running_tasks:
        print(f"ğŸ” Task: {task.description}")
        try:
            raw_results = await search_tool(task.description, num_results=settings.MAX_SEARCH_RESULTS)
        except Exception as e:
            dag.fail_task(task.id, str(e))
            continue
            
        if not raw_results:
            dag.complete_task(task.id, "No results found")
            continue
            
        snippets = "\n".join([f"[{i}] {r['url']}\n    {r['snippet'][:100]}..." for i, r in enumerate(raw_results)])
        select_resp = await simple_llm_call(prompts.search_result_selection(task.description, snippets, num_select=3), model=settings.MODEL_CHAT)
        selected_urls = parse_json_safe(select_resp) or [r["url"] for r in raw_results[:3]]
        
        print(f"ğŸ¯ [Selector] Selected: {selected_urls}")
        crawl_results = await crawl_urls(selected_urls)
        
        if crawl_results:
            collected_docs.extend(crawl_results)
            dag.complete_task(task.id, f"Scraped {len(crawl_results)} valid pages/files")
        else:
            dag.complete_task(task.id, "No valid content retrieved")

    if collected_docs:
        kb.add_documents(collected_docs, task_id=state["task_id"])
        print(f"ğŸ’¾ [Knowledge] Saved {len(collected_docs)} files.")
    
    dag.get_ready_tasks() 
    return {"plan": dag.to_state(), "knowledge_stats": [f"Added {len(collected_docs)} docs"]}

# ğŸŸ¢ æ ¸å¿ƒä¿®æ”¹ï¼šAnalyst èŠ‚ç‚¹ (ä¸€æœ¬ä¸€æœ¬è¯»)
async def node_analyst(state: ResearchState):
    print(f"--- [Analyst] Incremental Reading (Model: {settings.MODEL_CHAT}) ---")
    topic = state.get("clarified_intent", state["task"])
    
    # 1. è·å–æ–‡ä»¶åˆ—è¡¨
    files = kb.list_files(state["task_id"])
    if not files:
        return {"draft_report": "Error: No documents found to analyze."}

    # 2. åˆå§‹åŒ–ç¬”è®°
    running_notes = "ï¼ˆæš‚æ— è°ƒç ”ç¬”è®°ï¼Œç­‰å¾…é˜…è¯»ç¬¬ä¸€ä»½æ–‡æ¡£...ï¼‰"
    
    print(f"ğŸ“š [Analyst] Found {len(files)} documents. Reading sequentially...")
    
    # 3. é€ä¸ªé˜…è¯» (For Loop)
    for i, file_path in enumerate(files):
        # è¯»å–æ–‡ä»¶å†…å®¹
        doc_content = kb.read_file(file_path)
        if not doc_content: continue
        
        # æˆªæ–­å•ä¸ªæ–‡ä»¶å†…å®¹ï¼Œé˜²æ­¢æä¸ªåˆ«è¶…å¤§æ–‡ä»¶æº¢å‡º
        if len(doc_content) > 100000:
            doc_content = doc_content[:100000] + "\n...(file truncated)..."

        print(f"ğŸ“– Reading Doc {i+1}/{len(files)}: {os.path.basename(file_path)} ({len(doc_content)} chars)")
        
        # è°ƒç”¨ LLM æ›´æ–°ç¬”è®°
        prompt = prompts.analyst_incremental_reading(topic, running_notes, doc_content)
        # è¿™ä¸€æ­¥å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†è´¨é‡æé«˜
        running_notes = await simple_llm_call(prompt, model=settings.MODEL_CHAT)
    
    print("âœ… [Analyst] Reading complete. Generating Draft...")
    
    # 4. åŸºäºæœ€ç»ˆç¬”è®°ç”Ÿæˆè‰ç¨¿
    final_prompt = prompts.analyst_reasoning(topic, running_notes)
    draft = await simple_llm_call(final_prompt, model=settings.MODEL_CHAT)
    
    # 5. äº‹å®æ ¸æŸ¥
    verified = await VerificationAgent.verify_report(draft)
    
    return {"draft_report": verified}

async def node_critic(state: ResearchState):
    print("--- [Critic] Reviewing ---")
    topic = state.get("clarified_intent", state["task"])
    draft = state.get("draft_report", "")
    
    prompt = prompts.critic_evaluation(topic, draft)
    resp = await simple_llm_call(prompt, model=settings.MODEL_REASONING)
    
    default_eval = {"score": 5, "critique": "Parsing failed", "adjustment": "Retry"}
    eval_data = parse_json_safe(resp) or default_eval
    
    try: score = float(eval_data.get("score", 0))
    except: score = 5.0

    log = {
        "step_name": f"Iter-{state['iteration_count']}",
        "critique": eval_data.get("critique"),
        "score": score,
        "adjustment": eval_data.get("adjustment")
    }
    return {"reflection_logs": [log], "iteration_count": state["iteration_count"] + 1}

async def node_publisher(state: ResearchState):
    print("--- [Publisher] Generating Final Report ---")
    topic = state.get("clarified_intent", state["task"])
    
    # è·å– Analyst ç”Ÿæˆå¹¶ç»è¿‡ Verification çš„è‰ç¨¿
    draft = state.get("draft_report", "")
    
    if not draft:
        return {"final_report": "Error: No draft report generated."}

    # Publisher çš„å·¥ä½œæ˜¯ï¼šæ ¼å¼åŒ–ã€æ¶¦è‰²ã€å¢åŠ å‰è¨€/ç›®å½•
    # æˆ‘ä»¬å°† draft ä½œä¸ºæ ¸å¿ƒä¸Šä¸‹æ–‡ä¼ ç»™ LLM
    prompt = prompts.publisher_final_report(topic, draft)
    
    final_report = await simple_llm_call(prompt, model=settings.MODEL_CHAT)
    
    # ä¿å­˜
    saved_path = save_markdown_report(state["task"], final_report)
    if saved_path: 
        print(f"âœ… Report saved to: {saved_path}")
    
    return {"final_report": final_report}

# --- è·¯ç”±é€»è¾‘ ---

def route_planner(state: ResearchState) -> str:
    print("ğŸš¦ [Router] Deciding next step after Planner...")
    dag = DAGManager(state["plan"])
    running = [t for t in dag.tasks.values() if t.status == TaskStatus.RUNNING]
    if running:
        print(f"   -> Going to 'searcher' ({len(running)} tasks running)")
        return "searcher"
    if dag.is_all_completed():
        print("   -> Going to 'analyst' (All tasks completed)")
        return "analyst"
    print("   -> Fallback to 'analyst'")
    return "analyst"

def route_critic(state: ResearchState) -> str:
    if state["iteration_count"] >= state["max_iterations"]:
        print("ğŸ›‘ Max iterations reached -> Publisher")
        return "publisher"

    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šé˜²æ­¢ reflection_logs ä¸ºç©º
    if not state.get("reflection_logs"):
        print("âš ï¸ No reflection logs found -> Publisher")
        return "publisher"

    last_log = state["reflection_logs"][-1]
    if last_log.get("score", 0) >= 7.5:
        print("âœ… Score >= 7.5 -> Publisher")
        return "publisher"
    print("ğŸ”„ Score low -> Back to Planner")
    return "planner"

# --- æ„å»ºå›¾è°± ---

def build_graph():
    workflow = StateGraph(ResearchState)
    workflow.add_node("clarifier", node_clarifier)
    workflow.add_node("planner", node_planner)
    workflow.add_node("searcher", node_search_execute)
    workflow.add_node("analyst", node_analyst)
    workflow.add_node("critic", node_critic)
    workflow.add_node("publisher", node_publisher)
    
    workflow.set_entry_point("clarifier")
    workflow.add_edge("clarifier", "planner")
    workflow.add_conditional_edges("planner", route_planner, {"searcher": "searcher", "analyst": "analyst"})
    workflow.add_edge("searcher", "planner")
    workflow.add_edge("analyst", "critic")
    workflow.add_conditional_edges("critic", route_critic, {"planner": "planner", "publisher": "publisher"})
    workflow.add_edge("publisher", END)
    return workflow
</file>

</files>
