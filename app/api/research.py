# app/api/research.py
from fastapi import APIRouter
from sse_starlette.sse import EventSourceResponse
from app.modules.orchestrator.graph import build_graph
from app.core.config import settings
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
import aiosqlite
import asyncio
import json
import uuid
import traceback
# ğŸŸ¢ å¼•å…¥è¶…æ—¶æ§åˆ¶åº“ (è¯·ç¡®ä¿ pip install async_timeout)
from async_timeout import timeout 

router = APIRouter()

# è·å–æœªç¼–è¯‘çš„å›¾è°±æ„å»ºå™¨
workflow_builder = build_graph()

@router.get("/stream")
async def stream_research(topic: str):
    # ç”Ÿæˆå”¯ä¸€ä¼šè¯ ID
    thread_id = str(uuid.uuid4())
    task_id = thread_id
    config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": settings.MAX_RECURSION_LIMIT
    }

    async def event_generator():
        # åˆå§‹åŒ–çŠ¶æ€
        inputs = {
            "task_id": task_id,
            "task": topic,
            "clarified_intent": topic, # åˆå§‹æ—¶æ„å›¾ç­‰äºé¢˜ç›®
            "plan": [],
            "knowledge_graph": [],
            "reflection_logs": [],
            "iteration_count": 0,
            "max_iterations": 3,
            
            # å…¼å®¹å­—æ®µ
            "topic": topic,          # æš‚æ—¶ä¿ç•™ï¼Œgraph.py è¿˜åœ¨ç”¨
            "draft_report": "",      # æš‚æ—¶ä¿ç•™ï¼ŒAnalyst/Critic äº¤äº’ç”¨
            "final_report": "",      # æš‚æ—¶ä¿ç•™ï¼ŒPublisher ç”¨
        }
        
        try:
            # ğŸŸ¢ ä½¿ç”¨é…ç½®åŒ–çš„è¶…æ—¶æ—¶é—´
            # async_timeout ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šåœ¨è¶…æ—¶åæŠ›å‡º asyncio.TimeoutError
            async with timeout(settings.GLOBAL_TIMEOUT_SEC):
                
                # 1. æ˜¾å¼åˆ›å»ºè¿æ¥
                async with aiosqlite.connect(settings.CHECKPOINT_DB_PATH) as conn:
                    
                    # ğŸ©¹ã€ç³»ç»Ÿæ€§ä¿®å¤ / Monkey Patchã€‘
                    # ä¿®å¤ langgraph åœ¨ aiosqlite ä¸Šè°ƒç”¨ is_alive çš„å…¼å®¹æ€§é—®é¢˜
                    setattr(conn, "is_alive", lambda: True)
                    
                    # 2. å°†ä¿®å¤åçš„è¿æ¥ä¼ ç»™ Checkpointer
                    checkpointer = AsyncSqliteSaver(conn)
                    
                    # 3. ç¼–è¯‘å›¾è°±
                    graph = workflow_builder.compile(checkpointer=checkpointer)
                    
                    # 4. è¿è¡Œå›¾è°± (æµå¼)
                    async for event in graph.astream(inputs, config=config):
                        for node_name, state_update in event.items():
                            payload = {
                                "step": node_name,
                                "data": state_update
                            }
                            
                            json_str = json.dumps(
                                payload, 
                                default=str, 
                                ensure_ascii=False
                            )
                            
                            yield {
                                "event": "update",
                                "data": json_str
                            }
                            # ç¼“å†²ä¸€ä¸‹ï¼Œé¿å…å‰ç«¯æ¸²æŸ“è¿‡å¿«å¡é¡¿
                            await asyncio.sleep(0.1)

                    yield {"event": "finish", "data": "DONE"}

        except asyncio.TimeoutError:
            print(f"â° Task timed out after {settings.GLOBAL_TIMEOUT_SEC}s")
            error_payload = json.dumps(
                {"error": f"Global Timeout: Research stopped after {settings.GLOBAL_TIMEOUT_SEC} seconds."}, 
                ensure_ascii=False
            )
            yield {"event": "error", "data": error_payload}
                
        except Exception as e:
            print(f"âŒ Error in stream: {e}")
            traceback.print_exc()
            
            error_payload = json.dumps(
                {"error": str(e)}, 
                ensure_ascii=False
            )
            yield {"event": "error", "data": error_payload}

    return EventSourceResponse(event_generator())