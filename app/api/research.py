# app/api/research.py
from fastapi import APIRouter
from sse_starlette.sse import EventSourceResponse
from app.modules.orchestrator.graph import build_graph
from app.core.config import settings
# ğŸŸ¢ å¿…é¡»æ¢å› AsyncSqliteSaver
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver 
import aiosqlite
import asyncio
import json
import uuid
import traceback
from async_timeout import timeout 

router = APIRouter()

# è·å–æœªç¼–è¯‘çš„å›¾è°±æ„å»ºå™¨
workflow_builder = build_graph()

@router.get("/stream")
async def stream_research(topic: str, thread_id: str = None):
    """
    æµå¼æ·±åº¦ç ”ç©¶æ¥å£

    Args:
        topic: ç ”ç©¶ä¸»é¢˜
        thread_id: å¯é€‰å‚æ•°ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚
                  - é¦–æ¬¡è¯·æ±‚ï¼šä¸ä¼ æ­¤å‚æ•°ï¼Œç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆæ–°çš„ thread_id
                  - ç»­ä¼ è¯·æ±‚ï¼šä¼ å…¥ä¹‹å‰è¿”å›çš„ thread_idï¼Œå¯æ¢å¤ä¹‹å‰çš„ä¼šè¯çŠ¶æ€
    """
    # å¦‚æœå‰ç«¯æœªæä¾› thread_idï¼Œåˆ™ç”Ÿæˆæ–°çš„ UUID
    thread_id = thread_id or str(uuid.uuid4())
    task_id = thread_id  # task_id åŒæ­¥ä½¿ç”¨ thread_id

    config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": settings.MAX_RECURSION_LIMIT
    }

    async def event_generator():
        # åˆå§‹åŒ–çŠ¶æ€
        inputs = {
            "task_id": task_id,
            "task": topic,
            "clarified_intent": topic,
            "plan": [],
            "knowledge_graph": [],
            "reflection_logs": [],
            "iteration_count": 0,
            "max_iterations": 3,
            "topic": topic,          
            "draft_report": "",      
            "final_report": "",     
        }
        
        try:
            async with timeout(settings.GLOBAL_TIMEOUT_SEC):
                
                print(f"ğŸš€ [System] Starting research task: {task_id} (Async + WAL Mode)")
                
                # ğŸŸ¢ 1. ä½¿ç”¨å¼‚æ­¥è¿æ¥
                async with aiosqlite.connect(settings.CHECKPOINT_DB_PATH) as conn:
                    
                    # ğŸ›¡ï¸ã€å…³é”®é˜²æ­»é”é…ç½®ã€‘å¼€å¯ WAL æ¨¡å¼å’Œè¶…æ—¶è®¾ç½®
                    # è¿™å…è®¸è¯»å†™å¹¶å‘ï¼Œå½»åº•è§£å†³ä¹‹å‰çš„å¡æ­»é—®é¢˜
                    await conn.execute("PRAGMA journal_mode=WAL;")
                    await conn.execute("PRAGMA synchronous=NORMAL;")
                    await conn.execute("PRAGMA busy_timeout=30000;") # ç­‰å¾… 30s è€Œä¸æ˜¯ç«‹åˆ»æŠ¥é”™
                    await conn.commit()
                    
                    # ğŸ©¹ å…¼å®¹æ€§è¡¥ä¸ (é˜²æ­¢éƒ¨åˆ†ç‰ˆæœ¬çš„ LangGraph æŠ¥é”™)
                    setattr(conn, "is_alive", lambda: True)
                    
                    # 2. åˆ›å»ºå¼‚æ­¥ Checkpointer
                    checkpointer = AsyncSqliteSaver(conn)
                    
                    # 3. ç¼–è¯‘å›¾è°±
                    graph = workflow_builder.compile(checkpointer=checkpointer)
                    
                    # 4. è¿è¡Œå›¾è°± (astream å¿…é¡»é…å¯¹å¼‚æ­¥ checkpointer)
                    async for event in graph.astream(inputs, config=config):
                        for node_name, state_update in event.items():
                            payload = {
                                "step": node_name,
                                "data": state_update
                            }
                            
                            json_str = json.dumps(
                                payload, 
                                default=str, 
                                ensure_ascii=False
                            )
                            
                            yield {
                                "event": "update",
                                "data": json_str
                            }
                            # ç¼“å†²ä¸€ä¸‹
                            await asyncio.sleep(0.1)

                yield {"event": "finish", "data": "DONE"}

        except asyncio.TimeoutError:
            print(f"â° Task timed out after {settings.GLOBAL_TIMEOUT_SEC}s")
            error_payload = json.dumps(
                {"error": f"Global Timeout: Research stopped after {settings.GLOBAL_TIMEOUT_SEC} seconds."}, 
                ensure_ascii=False
            )
            yield {"event": "error", "data": error_payload}
                
        except Exception as e:
            print(f"âŒ Error in stream: {e}")
            traceback.print_exc()
            error_payload = json.dumps({"error": str(e)}, ensure_ascii=False)
            yield {"event": "error", "data": error_payload}

    return EventSourceResponse(event_generator())