# app/modules/perception/search.py
import asyncio
import functools
import random
from typing import List, Dict
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# ğŸŸ¢ å¼•å…¥æˆç†Ÿçš„å¼€æºåº“
import arxiv
from github import Github, Auth
import wikipedia

from app.core.config import settings

# --- 1. arXiv æœç´¢ (åŸºäº arxiv åº“) ---
def _sync_arxiv_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] arXiv æœç´¢é€»è¾‘"""
    print(f"ğŸ“š [arXiv] Searching: {query}...")
    try:
        # æ„é€ æœç´¢å®¢æˆ·ç«¯
        client = arxiv.Client()
        search = arxiv.Search(
            query=query,
            max_results=limit,
            sort_by=arxiv.SortCriterion.Relevance
        )
        
        results = []
        for r in client.results(search):
            results.append({
                "url": r.pdf_url, # ç›´æ¥ç»™ PDF é“¾æ¥ï¼Œé…åˆæˆ‘ä»¬çš„ PDF è§£æå™¨
                "title": f"[arXiv] {r.title}",
                "snippet": f"Published: {r.published.date()}\nAbstract: {r.summary[:500]}...",
                "source": "arxiv"
            })
        return results
    except Exception as e:
        print(f"âš ï¸ [arXiv] Error: {e}")
        return []

async def _search_arxiv(query: str, limit: int = 3) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_ARXIV: return []
    return await asyncio.to_thread(_sync_arxiv_search, query, limit)


# --- 2. GitHub æœç´¢ (åŸºäº PyGithub åº“) ---
def _sync_github_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] GitHub æœç´¢é€»è¾‘"""
    print(f"ğŸ’» [GitHub] Searching: {query}...")
    try:
        # é‰´æƒ (å¼ºçƒˆå»ºè®®é…ç½® Tokenï¼Œå¦åˆ™é™åˆ¶æä¸¥)
        auth = Auth.Token(settings.GITHUB_TOKEN) if settings.GITHUB_TOKEN else None
        g = Github(auth=auth)
        
        # æœç´¢ä»“åº“
        repos = g.search_repositories(query=query, sort="stars", order="desc")
        
        results = []
        # PyGithub çš„åˆ†é¡µæ˜¯æ‡’åŠ è½½çš„ï¼Œåªå–å‰ limit ä¸ª
        for i, repo in enumerate(repos):
            if i >= limit: break
            
            results.append({
                "url": repo.html_url,
                "title": f"[GitHub] {repo.full_name} ({repo.stargazers_count}â­)",
                "snippet": f"Language: {repo.language}\nDescription: {repo.description}\n(Readme will be crawled)",
                "source": "github"
            })
        
        g.close()
        return results
    except Exception as e:
        print(f"âš ï¸ [GitHub] Error: {e}")
        return []

async def _search_github(query: str, limit: int = 3) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_GITHUB: return []
    return await asyncio.to_thread(_sync_github_search, query, limit)


# --- 3. Wikipedia æœç´¢ (åŸºäº wikipedia åº“) ---
def _sync_wiki_search(query: str, limit: int) -> List[Dict]:
    """[åŒæ­¥] Wiki æœç´¢é€»è¾‘"""
    print(f"ğŸ“– [Wiki] Searching: {query}...")
    try:
        # ä¼˜å…ˆå°è¯•ä¸­æ–‡ï¼Œè‹¥æ— ç»“æœå¯è€ƒè™‘å›é€€è‹±æ–‡ (æ­¤å¤„ç®€åŒ–ä¸ºä¸­æ–‡)
        wikipedia.set_lang("zh")
        
        # 1. æœç´¢è¯æ¡æ ‡é¢˜
        search_results = wikipedia.search(query, results=limit)
        if not search_results:
            # å›é€€åˆ°è‹±æ–‡
            wikipedia.set_lang("en")
            search_results = wikipedia.search(query, results=limit)
            
        final_results = []
        for title in search_results:
            try:
                # 2. è·å–è¯æ¡è¯¦æƒ…
                # auto_suggest=False é˜²æ­¢è‡ªåŠ¨çº é”™å¯¼è‡´æœåˆ°ä¸ç›¸å…³çš„
                page = wikipedia.page(title, auto_suggest=False)
                
                final_results.append({
                    "url": page.url,
                    "title": f"[Wiki] {page.title}",
                    "snippet": page.summary[:500] + "...",
                    "source": "wiki"
                })
            except wikipedia.DisambiguationError as e:
                # æ­§ä¹‰é¡µé¢ï¼Œå–ç¬¬ä¸€ä¸ªé€‰é¡¹é‡è¯•
                try:
                    page = wikipedia.page(e.options[0], auto_suggest=False)
                    final_results.append({
                        "url": page.url,
                        "title": f"[Wiki] {page.title}",
                        "snippet": page.summary[:500] + "...",
                        "source": "wiki"
                    })
                except: pass
            except wikipedia.PageError:
                pass # é¡µé¢ä¸å­˜åœ¨
                
        return final_results
    except Exception as e:
        print(f"âš ï¸ [Wiki] Error: {e}")
        return []

async def _search_wiki(query: str, limit: int = 2) -> List[Dict]:
    """[å¼‚æ­¥åŒ…è£…] æ”¾å…¥çº¿ç¨‹æ± æ‰§è¡Œ"""
    if not settings.ENABLE_WIKI: return []
    return await asyncio.to_thread(_sync_wiki_search, query, limit)


# --- 4. Web æœç´¢ (Tavily) - æ”¯æŒå¤š Key è½®è¯¢ ---
async def _search_web_tavily(query: str, limit: int) -> List[Dict]:
    from app.core.config import settings
    # éšæœºé€‰æ‹©ä¸€ä¸ª API Keyï¼Œå®ç°è´Ÿè½½å‡è¡¡
    api_key = random.choice(settings.TAVILY_API_KEYS) if settings.TAVILY_API_KEYS else None
    if not api_key: return []
    
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.post(
                "https://api.tavily.com/search",
                json={"api_key": api_key, "query": query, "max_results": limit, "search_depth": "basic"},
                timeout=15.0
            )
            resp.raise_for_status()
            data = resp.json()
            return [{
                "url": r["url"], 
                "title": r["title"], 
                "snippet": r["content"], 
                "source": "web"
            } for r in data.get("results", [])]
    except Exception as e:
        print(f"âš ï¸ [Web] Error: {e}")
        return []


# --- 5. èšåˆå…¥å£ ---
async def search_generic(query: str, num_results: int = 5) -> List[Dict[str, str]]:
    """
    [æ··åˆæœç´¢ V2] åŸºäºæˆç†Ÿ SDK çš„å¹¶è¡Œæœç´¢
    """
    print(f"ğŸ” [Hybrid Search] Dispatching: {query}...")
    
    # å®šä¹‰ä»»åŠ¡ï¼šåŒæ—¶è§¦å‘ 4 è·¯æœç´¢
    tasks = [
        _search_arxiv(query, limit=settings.Result_Count_Arxiv),
        _search_github(query, limit=settings.Result_Count_Github),
        _search_wiki(query, limit=settings.Result_Count_Wiki),
        _search_web_tavily(query, limit=settings.Result_Count_Web)
    ]
    
    # å¹¶å‘æ‰§è¡Œ (è€—æ—¶å–å†³äºæœ€æ…¢çš„é‚£ä¸ªï¼Œé€šå¸¸æ˜¯ Web æˆ– GitHub)
    results_list = await asyncio.gather(*tasks)
    
    # å±•å¹³ä¸å»é‡
    all_results = []
    seen_urls = set()
    
    for res_group in results_list:
        for r in res_group:
            if r['url'] not in seen_urls:
                seen_urls.add(r['url'])
                all_results.append(r)
            
    print(f"âœ… [Hybrid Search] Found {len(all_results)} total results")
    return all_results

# å…¼å®¹å¯¼å‡º
search_tool = search_generic