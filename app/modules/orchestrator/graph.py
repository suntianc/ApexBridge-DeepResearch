# app/modules/orchestrator/graph.py

from langgraph.graph import StateGraph, END
import json,os

from app.core.config import settings
from app.core.utils import parse_json_safe
from app.modules.orchestrator.state import ResearchState
from app.modules.orchestrator.dag import DAGManager, TaskStatus
from app.modules.perception.search import search_generic as search_tool
from app.modules.perception.crawler import crawl_urls
from app.core.llm import simple_llm_call
# å¼•å…¥æ–°çš„æ–‡ä»¶å­˜å‚¨
from app.modules.knowledge.file_store import FileKnowledgeStore
from app.modules.insight.prompts import prompts
from app.modules.verification.verification_agent import VerificationAgent
from app.modules.utils.file_utils import save_markdown_report

# åˆå§‹åŒ–æ–‡ä»¶å­˜å‚¨
kb = FileKnowledgeStore()

# --- è¾…åŠ©å‡½æ•° ---

def log_step(step_name: str, content: dict):
    print(f"\nğŸš€ [Step: {step_name}]")
    try:
        text = json.dumps(content, indent=2, ensure_ascii=False, default=str)
        if len(text) > 2000:
            print(text[:2000] + "\n... (truncated)")
        else:
            print(text)
    except:
        print(str(content)[:2000])
    print("-" * 50)

# --- èŠ‚ç‚¹é€»è¾‘ ---

async def node_clarifier(state: ResearchState):
    print("--- [Clarifier] Checking Ambiguity ---")
    if state.get("clarified_intent"): return {}
    prompt = prompts.clarification_check(state["task"])
    response = await simple_llm_call(prompt, model=settings.MODEL_REASONING)
    result = parse_json_safe(response)
    
    if result and not result.get("is_clear", True):
        assumptions = result.get("assumptions", "Default assumptions")
        questions = result.get("questions", [])
        print(f"âš ï¸ Ambiguity Detected: {questions}")
        print(f"ğŸ¤– Auto-resolving: {assumptions}")
        new_intent = f"{state['task']} (Context: {assumptions})"
        return {"needs_clarification": True, "clarified_intent": new_intent, "clarification_history": questions}
    return {"needs_clarification": False, "clarified_intent": state["task"]}

async def node_planner(state: ResearchState):
    print(f"--- [Planner] (Model: {settings.MODEL_REASONING}) ---")
    dag = DAGManager(state["plan"])
    model_to_use = settings.MODEL_REASONING
    intent = state.get("clarified_intent", state["task"])
    
    # 1. å¤§çº²ç”Ÿæˆ
    current_outline = state.get("outline", [])
    if not current_outline:
        print("ğŸ“ [Planner] Generating Research Outline...")
        outline_resp = await simple_llm_call(prompts.outline_generation(state["task"], intent), model=model_to_use)
        current_outline = parse_json_safe(outline_resp) or []
        print(f"ğŸ“‘ Outline: {current_outline}")
    
    # 2. ä»»åŠ¡ç”Ÿæˆ
    has_feedback = False
    if state["reflection_logs"]:
        last_log = state["reflection_logs"][-1]
        if last_log.get("score", 0) < 8.0:
            print(f"ğŸ”„ [Planner] Replanning based on critique...")
            has_feedback = True
            feedback_str = f"æ‰¹è¯„: {last_log.get('critique')}\nå»ºè®®: {last_log.get('adjustment')}"
            plan_str = json.dumps(dag.to_state(), ensure_ascii=False)
            resp = await simple_llm_call(prompts.planner_dag_replanning(intent, plan_str, feedback_str), model=model_to_use)
            new_tasks = parse_json_safe(resp) or []
            # é˜²å¾¡æ€§å¤„ç†
            if isinstance(new_tasks, list):
                for t in new_tasks:
                    if isinstance(t, dict) and "id" in t and "description" in t:
                        dag.add_task(t["id"], t["description"], t.get("dependencies", []))
    
    if not dag.tasks and not has_feedback:
        print("ğŸ“ [Planner] Generating Tasks from Outline...")
        plan_str = json.dumps(dag.to_state(), ensure_ascii=False)
        resp = await simple_llm_call(prompts.planner_tasks_from_outline(intent, current_outline, plan_str), model=model_to_use)
        new_tasks = parse_json_safe(resp) or []

        # é˜²å¾¡æ€§å¤„ç†ï¼šç¡®ä¿ new_tasks æ˜¯å­—å…¸åˆ—è¡¨
        if isinstance(new_tasks, list):
            valid_tasks = []
            for t in new_tasks:
                if isinstance(t, dict) and "id" in t and "description" in t:
                    valid_tasks.append(t)
                else:
                    print(f"âš ï¸ [Planner] Skipping invalid task format: {t}")
            for t in valid_tasks:
                dag.add_task(t["id"], t["description"], dependencies=t.get("dependencies", []), related_section=t.get("related_section"))
            
    ready_tasks = dag.get_ready_tasks()
    current_queries = [t.description for t in ready_tasks]
    for t in ready_tasks: dag.set_task_running(t.id)
    
    log_step("Planner", {"outline": current_outline, "plan": dag.to_state()})
    return {"outline": current_outline, "plan": dag.to_state(), "search_queries": current_queries}

async def node_search_execute(state: ResearchState):
    print("ğŸ”„ [Search Node] Entered...", flush=True)
    dag = DAGManager(state["plan"])
    running_tasks = [t for t in dag.tasks.values() if t.status == TaskStatus.RUNNING]
    
    if not running_tasks:
        print("âš ï¸ [Search Node] No running tasks found!")
        return {}

    print(f"--- [Search] Processing {len(running_tasks)} tasks ---", flush=True)
    collected_docs = []
    
    for task in running_tasks:
        print(f"ğŸ” Task: {task.description}")
        try:
            raw_results = await search_tool(task.description, num_results=settings.MAX_SEARCH_RESULTS)
        except Exception as e:
            dag.fail_task(task.id, str(e))
            continue
            
        if not raw_results:
            dag.complete_task(task.id, "No results found")
            continue
            
        snippets = "\n".join([f"[{i}] {r['url']}\n    {r['snippet'][:100]}..." for i, r in enumerate(raw_results)])
        select_resp = await simple_llm_call(prompts.search_result_selection(task.description, snippets, num_select=3), model=settings.MODEL_CHAT)
        selected_urls = parse_json_safe(select_resp) or [r["url"] for r in raw_results[:3]]
        
        print(f"ğŸ¯ [Selector] Selected: {selected_urls}")
        crawl_results = await crawl_urls(selected_urls)
        
        if crawl_results:
            collected_docs.extend(crawl_results)
            dag.complete_task(task.id, f"Scraped {len(crawl_results)} valid pages/files")
        else:
            dag.complete_task(task.id, "No valid content retrieved")

    if collected_docs:
        kb.add_documents(collected_docs, task_id=state["task_id"])
        print(f"ğŸ’¾ [Knowledge] Saved {len(collected_docs)} files.")
    
    dag.get_ready_tasks() 
    return {"plan": dag.to_state(), "knowledge_stats": [f"Added {len(collected_docs)} docs"]}

# ğŸŸ¢ æ ¸å¿ƒä¿®æ”¹ï¼šAnalyst èŠ‚ç‚¹ (ä¸€æœ¬ä¸€æœ¬è¯»)
async def node_analyst(state: ResearchState):
    print(f"--- [Analyst] Incremental Reading (Model: {settings.MODEL_CHAT}) ---")
    topic = state.get("clarified_intent", state["task"])
    
    # 1. è·å–æ–‡ä»¶åˆ—è¡¨
    files = kb.list_files(state["task_id"])
    if not files:
        return {"draft_report": "Error: No documents found to analyze."}

    # 2. åˆå§‹åŒ–ç¬”è®°
    running_notes = "ï¼ˆæš‚æ— è°ƒç ”ç¬”è®°ï¼Œç­‰å¾…é˜…è¯»ç¬¬ä¸€ä»½æ–‡æ¡£...ï¼‰"
    
    print(f"ğŸ“š [Analyst] Found {len(files)} documents. Reading sequentially...")
    
    # 3. é€ä¸ªé˜…è¯» (For Loop)
    for i, file_path in enumerate(files):
        # è¯»å–æ–‡ä»¶å†…å®¹
        doc_content = kb.read_file(file_path)
        if not doc_content: continue
        
        # æˆªæ–­å•ä¸ªæ–‡ä»¶å†…å®¹ï¼Œé˜²æ­¢æä¸ªåˆ«è¶…å¤§æ–‡ä»¶æº¢å‡º
        if len(doc_content) > 100000:
            doc_content = doc_content[:100000] + "\n...(file truncated)..."

        print(f"ğŸ“– Reading Doc {i+1}/{len(files)}: {os.path.basename(file_path)} ({len(doc_content)} chars)")
        
        # è°ƒç”¨ LLM æ›´æ–°ç¬”è®°
        prompt = prompts.analyst_incremental_reading(topic, running_notes, doc_content)
        # è¿™ä¸€æ­¥å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†è´¨é‡æé«˜
        running_notes = await simple_llm_call(prompt, model=settings.MODEL_CHAT)
    
    print("âœ… [Analyst] Reading complete. Generating Draft...")
    
    # 4. åŸºäºæœ€ç»ˆç¬”è®°ç”Ÿæˆè‰ç¨¿
    final_prompt = prompts.analyst_reasoning(topic, running_notes)
    draft = await simple_llm_call(final_prompt, model=settings.MODEL_CHAT)
    
    # 5. äº‹å®æ ¸æŸ¥
    verified = await VerificationAgent.verify_report(draft)
    
    return {"draft_report": verified}

async def node_critic(state: ResearchState):
    print("--- [Critic] Reviewing ---")
    topic = state.get("clarified_intent", state["task"])
    draft = state.get("draft_report", "")
    
    prompt = prompts.critic_evaluation(topic, draft)
    resp = await simple_llm_call(prompt, model=settings.MODEL_REASONING)
    
    default_eval = {"score": 5, "critique": "Parsing failed", "adjustment": "Retry"}
    eval_data = parse_json_safe(resp) or default_eval
    
    try: score = float(eval_data.get("score", 0))
    except: score = 5.0

    log = {
        "step_name": f"Iter-{state['iteration_count']}",
        "critique": eval_data.get("critique"),
        "score": score,
        "adjustment": eval_data.get("adjustment")
    }
    return {"reflection_logs": [log], "iteration_count": state["iteration_count"] + 1}

async def node_publisher(state: ResearchState):
    print("--- [Publisher] Generating Final Report ---")
    topic = state.get("clarified_intent", state["task"])
    
    # è·å– Analyst ç”Ÿæˆå¹¶ç»è¿‡ Verification çš„è‰ç¨¿
    draft = state.get("draft_report", "")
    
    if not draft:
        return {"final_report": "Error: No draft report generated."}

    # Publisher çš„å·¥ä½œæ˜¯ï¼šæ ¼å¼åŒ–ã€æ¶¦è‰²ã€å¢åŠ å‰è¨€/ç›®å½•
    # æˆ‘ä»¬å°† draft ä½œä¸ºæ ¸å¿ƒä¸Šä¸‹æ–‡ä¼ ç»™ LLM
    prompt = prompts.publisher_final_report(topic, draft)
    
    final_report = await simple_llm_call(prompt, model=settings.MODEL_CHAT)
    
    # ä¿å­˜
    saved_path = save_markdown_report(state["task"], final_report)
    if saved_path: 
        print(f"âœ… Report saved to: {saved_path}")
    
    return {"final_report": final_report}

# --- è·¯ç”±é€»è¾‘ ---

def route_planner(state: ResearchState) -> str:
    print("ğŸš¦ [Router] Deciding next step after Planner...")
    dag = DAGManager(state["plan"])
    running = [t for t in dag.tasks.values() if t.status == TaskStatus.RUNNING]
    if running:
        print(f"   -> Going to 'searcher' ({len(running)} tasks running)")
        return "searcher"
    if dag.is_all_completed():
        print("   -> Going to 'analyst' (All tasks completed)")
        return "analyst"
    print("   -> Fallback to 'analyst'")
    return "analyst"

def route_critic(state: ResearchState) -> str:
    if state["iteration_count"] >= state["max_iterations"]:
        print("ğŸ›‘ Max iterations reached -> Publisher")
        return "publisher"

    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šé˜²æ­¢ reflection_logs ä¸ºç©º
    if not state.get("reflection_logs"):
        print("âš ï¸ No reflection logs found -> Publisher")
        return "publisher"

    last_log = state["reflection_logs"][-1]
    if last_log.get("score", 0) >= 7.5:
        print("âœ… Score >= 7.5 -> Publisher")
        return "publisher"
    print("ğŸ”„ Score low -> Back to Planner")
    return "planner"

# --- æ„å»ºå›¾è°± ---

def build_graph():
    workflow = StateGraph(ResearchState)
    workflow.add_node("clarifier", node_clarifier)
    workflow.add_node("planner", node_planner)
    workflow.add_node("searcher", node_search_execute)
    workflow.add_node("analyst", node_analyst)
    workflow.add_node("critic", node_critic)
    workflow.add_node("publisher", node_publisher)
    
    workflow.set_entry_point("clarifier")
    workflow.add_edge("clarifier", "planner")
    workflow.add_conditional_edges("planner", route_planner, {"searcher": "searcher", "analyst": "analyst"})
    workflow.add_edge("searcher", "planner")
    workflow.add_edge("analyst", "critic")
    workflow.add_conditional_edges("critic", route_critic, {"planner": "planner", "publisher": "publisher"})
    workflow.add_edge("publisher", END)
    return workflow